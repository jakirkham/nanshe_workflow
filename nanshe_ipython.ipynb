{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test setup. Ignore warnings during production runs.\n",
        "\n",
        "%run ./setup_tests.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Specify input data\n",
        "\n",
        "* `data_dir` (`str`): Where the data is located. (change if data is not in the current directory, normally is)\n",
        "* `data` (`str`): HDF5 file to use as input data.\n",
        "* `data_basename` (`str`): Basename to use for intermediate and final result files.\n",
        "* `dataset` (`str`): HDF5 dataset to use as input data.\n",
        "\n",
        "</br>\n",
        "* `num_workers` (`int`): Number of workers for iPython Cluster. (default all cores excepting one for client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"\"\n",
        "data = \"data.tif\"\n",
        "data_basename = \"data\"\n",
        "dataset = \"images\"\n",
        "\n",
        "num_workers = None\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "data_ext = os.path.splitext(data)[1].lower()\n",
        "data_dir = os.path.abspath(data_dir)\n",
        "\n",
        "postfix_trim = \"_trim\"\n",
        "postfix_dn = \"_dn\"\n",
        "postfix_reg = \"_reg\"\n",
        "postfix_sub = \"_sub\"\n",
        "postfix_f_f0 = \"_f_f0\"\n",
        "postfix_wt = \"_wt\"\n",
        "postfix_norm = \"_norm\"\n",
        "postfix_dict = \"_dict\"\n",
        "postfix_post = \"_post\"\n",
        "postfix_rois = \"_rois\"\n",
        "postfix_traces = \"_traces\"\n",
        "postfix_proj = \"_proj\"\n",
        "postfix_html = \"_proj\"\n",
        "\n",
        "h5_ext = os.path.extsep + \"h5\"\n",
        "tiff_ext = os.path.extsep + \"tif\"\n",
        "zarr_ext = os.path.extsep + \"zarr\"\n",
        "html_ext = os.path.extsep + \"html\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure and startup Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.par import set_num_workers, startup_distributed\n",
        "\n",
        "num_workers = set_num_workers(num_workers)\n",
        "\n",
        "client = startup_distributed(num_workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define functions for computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.cm\n",
        "import matplotlib.pyplot\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mplview.core import MatplotlibViewer as MPLViewer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from builtins import range as irange\n",
        "\n",
        "import numpy\n",
        "import scipy\n",
        "import scipy.ndimage\n",
        "import h5py\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.ndimage as spim\n",
        "import h5py as hp\n",
        "\n",
        "import dask\n",
        "import dask.array\n",
        "import dask.array.fft\n",
        "import dask.distributed\n",
        "\n",
        "import dask.array as da\n",
        "\n",
        "import dask_imread\n",
        "import dask_ndfilters\n",
        "import dask_ndfourier\n",
        "\n",
        "import zarr\n",
        "\n",
        "import nanshe\n",
        "from nanshe.imp.segment import generate_dictionary\n",
        "\n",
        "import nanshe_workflow\n",
        "from nanshe_workflow.data import io_remove, dask_io_remove, dask_load_hdf5, dask_store_zarr, zip_zarr, open_zarr\n",
        "\n",
        "zarr.blosc.set_nthreads(1)\n",
        "zarr.blosc.use_threads = False\n",
        "client.run(zarr.blosc.set_nthreads, 1)\n",
        "client.run(setattr, zarr.blosc, \"use_threads\", False)\n",
        "\n",
        "logging.getLogger(\"nanshe\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.data import hdf5_to_zarr, zarr_to_hdf5\n",
        "from nanshe_workflow.data import save_tiff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import pyfftw.interfaces.numpy_fft as numpy_fft\n",
        "except ImportError:\n",
        "    import numpy.fft as numpy_fft\n",
        "\n",
        "rfftn = da.fft.fft_wrap(numpy_fft.rfftn)\n",
        "irfftn = da.fft.fft_wrap(numpy_fft.irfftn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.imp2 import extract_f0, wavelet_transform, renormalized_images, normalize_data\n",
        "\n",
        "from nanshe_workflow.par import halo_block_generate_dictionary_parallel\n",
        "from nanshe_workflow.imp import block_postprocess_data_parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.proj2 import compute_traces\n",
        "\n",
        "from nanshe_workflow.proj2 import compute_adj_harmonic_mean_projection\n",
        "from nanshe_workflow.proj2 import compute_min_projection\n",
        "from nanshe_workflow.proj2 import compute_max_projection\n",
        "\n",
        "from nanshe_workflow.proj2 import compute_moment_projections\n",
        "\n",
        "from nanshe_workflow.proj2 import norm_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Begin workflow. Set parameters and run each cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert TIFF/HDF5 to Zarr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dask_io_remove(data_basename + zarr_ext, client)\n",
        "\n",
        "if data_ext == tiff_ext:\n",
        "    a = dask_imread.imread(data)\n",
        "elif data_ext == h5_ext:\n",
        "    a = dask_load_hdf5(data, dataset)\n",
        "\n",
        "dask_store_zarr(data_basename + zarr_ext, [dataset], [a], client)\n",
        "\n",
        "del a"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import itertools\n",
        "import hashlib\n",
        "\n",
        "import dask\n",
        "import zarr\n",
        "\n",
        "from builtins import map as imap\n",
        "from builtins import range as irange\n",
        "\n",
        "\n",
        "def hash_chunk(dataset, chunk_id, hashname=\"sha1\"):\n",
        "    str_i = \".\".join(imap(str, chunk_id))\n",
        "\n",
        "    h = hashlib.new(hashname)\n",
        "\n",
        "    h.update(dataset.store[dataset.path + '/' + zarr.storage.array_meta_key])\n",
        "    h.update(dataset.chunk_store[dataset.path + '/' + str_i])\n",
        "\n",
        "    checksum = h.digest()\n",
        "\n",
        "    return checksum\n",
        "\n",
        "\n",
        "def hash_reduce(*hashes, hashname=\"sha1\"):\n",
        "    h = hashlib.new(hashname)\n",
        "\n",
        "    for each_hash in hashes:\n",
        "        h.update(each_hash)\n",
        "\n",
        "    checksum = h.digest()\n",
        "\n",
        "    return checksum\n",
        "\n",
        "\n",
        "def hash_dataset(dataset, hashname=\"sha1\"):\n",
        "    d = []\n",
        "    for i in itertools.product(*[irange(s) for s in dataset.cdata_shape]):\n",
        "        d.append(dask.delayed(hash_chunk)(dataset, i, hashname=hashname))\n",
        "\n",
        "    while len(d) > 1:\n",
        "        # Ensure there is an even number of hashes\n",
        "        if len(d) % 2:\n",
        "            d.append(d[-1])\n",
        "\n",
        "        # Pair them off for comparison\n",
        "        d2 = []\n",
        "        for i in irange(0, len(d), 2):\n",
        "            d2.append(dask.delayed(hash_reduce)(*d[i:i+2], hashname=hashname))\n",
        "        d = d2\n",
        "    d = d[0]\n",
        "\n",
        "    return d\n",
        "\n",
        "\n",
        "fn = data_basename + zarr_ext\n",
        "f = zarr.open_group(fn, \"r\")\n",
        "\n",
        "imgs = f[dataset]\n",
        "\n",
        "checksum_sha1 = hash_dataset(f[dataset], hashname=\"sha1\").compute()\n",
        "checksum_md5 = hashlib.md5(checksum_sha1).hexdigest()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bytes is not str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import binascii\n",
        "\n",
        "binascii.hexlify(checksum_sha1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgs.attrs.get(\"__dask_name__\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pdoc da.from_array"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Input Data\n",
        "\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "da_imgs.name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "norm_frames = 100\n",
        "\n",
        "fn = data_basename + zarr_ext\n",
        "\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "f = zarr.open_group(fn, \"r\")\n",
        "\n",
        "imgs = f[dataset]\n",
        "da_imgs = da.from_array(imgs, chunks=(norm_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max], lock=False, compute=False)\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Trimming\n",
        "\n",
        "* `front` (`int`): amount to trim off the front\n",
        "* `back` (`int`): amount to trim off the back\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "front = 0\n",
        "back = 0\n",
        "\n",
        "block_frames = 1\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_trim + zarr_ext, client)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "f = zarr.open_group(data_basename + zarr_ext, \"r\")\n",
        "imgs = f[dataset]\n",
        "da_imgs = da.from_array(imgs, chunks=(block_frames,) + imgs.shape[1:])\n",
        "\n",
        "# Trim frames from front and back\n",
        "da_imgs_trim = da_imgs[front:len(da_imgs)-back]\n",
        "\n",
        "# Store denoised data\n",
        "dask_store_zarr(data_basename + postfix_trim + zarr_ext, [\"images\"], [da_imgs_trim], client)\n",
        "\n",
        "\n",
        "# View results\n",
        "fn = data_basename + postfix_trim + zarr_ext\n",
        "\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "f = zarr.open_group(fn, \"r\")\n",
        "\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(norm_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max], lock=False, compute=False)\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Denoising\n",
        "\n",
        "* `med_filt_size` (`int`): footprint size for median filter\n",
        "* `norm_filt_sigma` (`int`/`float`): sigma for Gaussian filter\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "med_filt_size = 3\n",
        "norm_filt_sigma = 10\n",
        "\n",
        "block_frames = 1\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_dn + zarr_ext, client)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "f = zarr.open_group(data_basename + postfix_trim + zarr_ext, \"r\")\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(block_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "# Median filter frames\n",
        "da_imgs_medf = dask_ndfilters.median_filter(\n",
        "    da_imgs_flt, (1,) + (da_imgs_flt.ndim - 1) * (med_filt_size,)\n",
        ")\n",
        "\n",
        "# Compute the Gaussian filter of frames\n",
        "da_imgs_smoothed = dask_ndfilters.gaussian_filter(\n",
        "    da_imgs_medf, (0,) + (da_imgs_medf.ndim - 1) * (norm_filt_sigma,)\n",
        ")\n",
        "\n",
        "# Apply high pass filter to images\n",
        "da_imgs_filt = da_imgs_medf - da_imgs_smoothed\n",
        "\n",
        "# Reset minimum to original value.\n",
        "da_imgs_filt += da_imgs.min() - da_imgs_filt.min()\n",
        "\n",
        "# Store denoised data\n",
        "dask_store_zarr(data_basename + postfix_dn + zarr_ext, [\"images\"], [da_imgs_filt], client)\n",
        "\n",
        "\n",
        "# View results\n",
        "fn = data_basename + postfix_dn + zarr_ext\n",
        "\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "f = zarr.open_group(fn, \"r\")\n",
        "\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(norm_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max], lock=False, compute=False)\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Registration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fourier_shift_wrap(array, shift):\n",
        "    result = numpy.empty_like(array)\n",
        "    for i in irange(len(array)):\n",
        "        result[i] = spim.fourier_shift(array[i], shift[0][i])\n",
        "    return result\n",
        "\n",
        "\n",
        "def find_best_match(matches):\n",
        "    best_match = numpy.zeros(\n",
        "        matches.shape[:1],\n",
        "        dtype=matches.dtype\n",
        "    )\n",
        "    if matches.size:\n",
        "        i = numpy.argmin((matches ** 2).sum(axis=0))\n",
        "        best_match = matches[:, i]\n",
        "\n",
        "    return best_match\n",
        "\n",
        "\n",
        "def compute_offset(match_mask):\n",
        "    match_mask = match_mask[0][0]\n",
        "\n",
        "    result = numpy.empty((len(match_mask), match_mask.ndim - 1), dtype=int)\n",
        "    for i in irange(len(match_mask)):\n",
        "        match_mask_i = match_mask[i]\n",
        "\n",
        "        frame_shape = np.array(match_mask_i.shape)\n",
        "        half_frame_shape = frame_shape // 2\n",
        "\n",
        "        matches = np.array(match_mask_i.nonzero())\n",
        "        above = (matches > half_frame_shape[:, None]).astype(matches.dtype)\n",
        "        matches -= above * frame_shape[:, None]\n",
        "\n",
        "        result[i] = find_best_match(matches)\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_reps = 5\n",
        "tmpl_hist_wght = 0.25\n",
        "thld_rel_dist = 0.0\n",
        "\n",
        "block_frames = 1\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_reg + zarr_ext, client)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "f = zarr.open_group(data_basename + postfix_dn + zarr_ext, \"r\")\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(block_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "# Create frame shape arrays\n",
        "frame_shape = np.array(da_imgs_flt.shape[1:], dtype=int)\n",
        "half_frame_shape = frame_shape // 2\n",
        "frame_shape = da.asarray(frame_shape)\n",
        "half_frame_shape = da.asarray(half_frame_shape)\n",
        "\n",
        "# Compute the FFT of frames and template\n",
        "da_imgs_fft = rfftn(da_imgs_flt, axes=tuple(irange(1, imgs.ndim)))\n",
        "da_imgs_fft_tmplt = da_imgs_fft.mean(axis=0, keepdims=True)\n",
        "\n",
        "# Initialize\n",
        "i = 0\n",
        "avg_rel_dist = 1.0\n",
        "tmpl_hist_wght = da_imgs_flt.dtype.type(tmpl_hist_wght)\n",
        "shifts = da.zeros(\n",
        "    (len(da_imgs_flt), da_imgs_flt.ndim - 1),\n",
        "    dtype=int,\n",
        "    chunks=(1, da_imgs_flt.ndim - 1)\n",
        ")\n",
        "\n",
        "# Persist FFT of frames and template\n",
        "da_imgs_fft, da_imgs_fft_tmplt = client.persist([da_imgs_fft, da_imgs_fft_tmplt])\n",
        "\n",
        "while avg_rel_dist > thld_rel_dist and i < num_reps:\n",
        "    # Compute the shifted frames\n",
        "    shifted_frames = da.atop(\n",
        "        fourier_shift_wrap,\n",
        "        (0,) + tuple(irange(1, da_imgs_fft.ndim)),\n",
        "        da_imgs_fft,\n",
        "        (0,) + tuple(irange(1, da_imgs_fft.ndim)),\n",
        "        shifts,\n",
        "        (0, da_imgs_fft.ndim),\n",
        "        dtype=da_imgs_fft.dtype\n",
        "    )\n",
        "\n",
        "    # Compute the template FFT\n",
        "    da_imgs_fft_tmplt = (\n",
        "        tmpl_hist_wght * da_imgs_fft_tmplt +\n",
        "        (1 - tmpl_hist_wght) * shifted_frames.mean(axis=0, keepdims=True)\n",
        "    )\n",
        "\n",
        "    # Free connected persisted values\n",
        "    del shifted_frames\n",
        "\n",
        "    # Find the best overlap with the template.\n",
        "    overlap = irfftn(\n",
        "        da_imgs_fft * da_imgs_fft_tmplt,\n",
        "        s=da_imgs_flt.shape[1:],\n",
        "        axes=tuple(irange(1, imgs.ndim))\n",
        "    )\n",
        "    overlap_max = overlap.max(axis=tuple(irange(1, imgs.ndim)), keepdims=True)\n",
        "    overlap_max_match = (overlap == overlap_max)\n",
        "\n",
        "    # Compute the shift for each frame.\n",
        "    old_shifts = shifts\n",
        "    shifts = da.atop(\n",
        "        compute_offset,\n",
        "        (0, overlap_max_match.ndim),\n",
        "        overlap_max_match.rechunk(dict(enumerate(overlap_max_match.shape[1:], 1))),\n",
        "        tuple(irange(0, overlap_max_match.ndim)),\n",
        "        dtype=int,\n",
        "        new_axes={overlap_max_match.ndim: overlap_max_match.ndim - 1}\n",
        "    )\n",
        "\n",
        "    # Free connected persisted values\n",
        "    del overlap\n",
        "    del overlap_max\n",
        "    del overlap_max_match\n",
        "\n",
        "    # Remove any collective frame drift.\n",
        "    drift = shifts.mean(axis=0, keepdims=True).round().astype(shifts.dtype)\n",
        "    shifts = shifts - drift\n",
        "\n",
        "    # Free connected persisted values\n",
        "    del drift\n",
        "\n",
        "    # Find shift change.\n",
        "    diff_shifts = shifts - old_shifts\n",
        "    rel_diff_shifts = (\n",
        "        diff_shifts.astype(da_imgs_flt.dtype) / \n",
        "        frame_shape.astype(da_imgs_flt.dtype) /\n",
        "        (da_imgs_flt.dtype.type(len(frame_shape)) ** 0.5)\n",
        "    )\n",
        "    rel_dist_shifts = (rel_diff_shifts ** 2.0).sum(axis=1) ** 0.5\n",
        "    avg_rel_dist = rel_dist_shifts.sum() / da_imgs_flt.dtype.type(len(shifts))\n",
        "\n",
        "    # Free old shifts\n",
        "    del old_shifts\n",
        "\n",
        "    # Free connected persisted values\n",
        "    del diff_shifts\n",
        "    del rel_diff_shifts\n",
        "    del rel_dist_shifts\n",
        "\n",
        "    # Persist values needed for the next iteration (and end of this one).\n",
        "    da_imgs_fft_tmplt, shifts, avg_rel_dist = client.persist([da_imgs_fft_tmplt, shifts, avg_rel_dist])\n",
        "\n",
        "    # Compute change\n",
        "    status = client.compute(avg_rel_dist)\n",
        "    dask.distributed.progress(status, notebook=False)\n",
        "    print(\"\")\n",
        "    avg_rel_dist = status.result()\n",
        "    i += 1\n",
        "\n",
        "    # Show change\n",
        "    print((i, avg_rel_dist))\n",
        "\n",
        "# Drop unneeded items\n",
        "del frame_shape\n",
        "del half_frame_shape\n",
        "del da_imgs_flt\n",
        "del da_imgs_fft\n",
        "del da_imgs_fft_tmplt\n",
        "\n",
        "# Truncate shifted part of each frame\n",
        "da_imgs_trunc = []\n",
        "da_imgs_trunc_shape = da_imgs.shape[1:]\n",
        "for i in irange(len(da_imgs)):\n",
        "    slice_i = [i]\n",
        "    shift_i = numpy.array(shifts[i])[()]\n",
        "    for j in irange(len(shift_i)):\n",
        "        shifts_ij = shift_i[j]\n",
        "        if shifts_ij < 0:\n",
        "            slice_i.append(slice(-shifts_ij, None))\n",
        "        elif shifts_ij > 0:\n",
        "            slice_i.append(slice(None, -shifts_ij))\n",
        "        else:\n",
        "            slice_i.append(slice(None))\n",
        "    slice_i = tuple(slice_i)\n",
        "    da_imgs_trunc.append(da_imgs[slice_i])\n",
        "    da_imgs_trunc_shape = tuple(np.minimum(\n",
        "        da_imgs_trunc_shape, da_imgs_trunc[-1].shape\n",
        "    ))\n",
        "\n",
        "# Free raw data\n",
        "del da_imgs\n",
        "\n",
        "# Truncate all frames to smallest one\n",
        "da_imgs_trunc_cut = tuple(map(\n",
        "    lambda s: slice(None, s), da_imgs_trunc_shape\n",
        "))\n",
        "for i in irange(len(da_imgs_trunc)):\n",
        "    da_imgs_trunc[i] = da_imgs_trunc[i][da_imgs_trunc_cut]\n",
        "da_imgs_trunc = da.stack(da_imgs_trunc)\n",
        "\n",
        "# Store registered data\n",
        "dask_store_zarr(\n",
        "    data_basename + postfix_reg + zarr_ext,\n",
        "    [\"images\", \"shifts\"],\n",
        "    [da_imgs_trunc, shifts],\n",
        "    client\n",
        ")\n",
        "\n",
        "# Free truncated frames and shifts\n",
        "del da_imgs_trunc\n",
        "del shifts\n",
        "\n",
        "\n",
        "# View results\n",
        "fn = data_basename + postfix_reg + zarr_ext\n",
        "\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "f = zarr.open_group(fn, \"r\")\n",
        "\n",
        "imgs = f[\"images\"]\n",
        "shifts = f[\"shifts\"]\n",
        "\n",
        "da_imgs = da.from_array(imgs, chunks=(norm_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max], lock=False, compute=False)\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "fig, axs = plt.subplots(nrows=shifts.shape[1], sharex=True)\n",
        "fig.subplots_adjust(hspace=0.0)\n",
        "for i in range(shifts.shape[1]):\n",
        "    axs[i].plot(shifts[:, i][...])\n",
        "    axs[i].set_ylabel(\"%s (px)\" % chr(ord(\"X\") + shifts.shape[1] - i - 1))\n",
        "    axs[i].yaxis.set_tick_params(width=1.5)\n",
        "    [v.set_linewidth(2) for v in axs[i].spines.values()]\n",
        "axs[-1].set_xlabel(\"Frame (#)\")\n",
        "axs[-1].set_xlim((0, shifts.shape[0] - 1))\n",
        "axs[-1].xaxis.set_tick_params(width=1.5)\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Projections\n",
        "\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_frames = 100\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_proj + zarr_ext, client)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "f = zarr.open_group(data_basename + postfix_reg + zarr_ext, \"r\")\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(block_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_proj_hmean = compute_adj_harmonic_mean_projection(da_imgs_flt)\n",
        "\n",
        "da_imgs_proj_max = compute_max_projection(da_imgs_flt)\n",
        "\n",
        "da_imgs_proj_mean, da_imgs_proj_std = compute_moment_projections(da_imgs_flt, 3)[1:]\n",
        "da_imgs_proj_std -= da_imgs_proj_mean**2\n",
        "da_imgs_proj_std = da.sqrt(da_imgs_proj_std)\n",
        "\n",
        "# Store denoised data\n",
        "dask_store_zarr(\n",
        "    data_basename + postfix_proj + zarr_ext,\n",
        "    [\"hmean\", \"max\", \"mean\", \"std\"],\n",
        "    [da_imgs_proj_hmean, da_imgs_proj_max, da_imgs_proj_mean, da_imgs_proj_std],\n",
        "    client\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtract Projection\n",
        "\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_frames = 100\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_sub + zarr_ext, client)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "f = zarr.open_group(data_basename + postfix_reg + zarr_ext, \"r\")\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(block_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_sub = da_imgs_flt - compute_adj_harmonic_mean_projection(da_imgs_flt)\n",
        "da_imgs_sub -= da_imgs_sub.min()\n",
        "\n",
        "# Store denoised data\n",
        "dask_store_zarr(data_basename + postfix_sub + zarr_ext, [\"images\"], [da_imgs_sub], client)\n",
        "\n",
        "\n",
        "# View results\n",
        "fn = data_basename + postfix_sub + zarr_ext\n",
        "\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "f = zarr.open_group(fn, \"r\")\n",
        "\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(norm_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max], lock=False, compute=False)\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Background Subtraction\n",
        "\n",
        "* `half_window_size` (`int`): the rank filter window size is `2*half_window_size+1`.\n",
        "* `which_quantile` (`float`): which quantile to return from the rank filter.\n",
        "* `temporal_smoothing_gaussian_filter_stdev` (`float`): stdev for gaussian filter to convolve over time.\n",
        "* `temporal_smoothing_gaussian_filter_window_size` (`float`): window for gaussian filter to convolve over time. (Measured in standard deviations)\n",
        "* `spatial_smoothing_gaussian_filter_stdev` (`float`): stdev for gaussian filter to convolve over space.\n",
        "* `spatial_smoothing_gaussian_filter_window_size` (`float`): window for gaussian filter to convolve over space. (Measured in standard deviations)\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel).\n",
        "* `block_space` (`int`): extent of each spatial dimension for each block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "half_window_size = 100\n",
        "which_quantile = 0.5\n",
        "temporal_smoothing_gaussian_filter_stdev = 0.0\n",
        "temporal_smoothing_gaussian_filter_window_size = 0\n",
        "spatial_smoothing_gaussian_filter_stdev = 0.0\n",
        "spatial_smoothing_gaussian_filter_window_size = 0\n",
        "\n",
        "block_frames = 1000\n",
        "block_space = 100\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_f_f0 + zarr_ext, client)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "f = zarr.open_group(data_basename + postfix_sub + zarr_ext, \"r\")\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(\n",
        "    imgs, chunks=(block_frames,) + (imgs.ndim - 1) * (block_space,)\n",
        ")\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "bias = 1 - da_imgs_flt.min()\n",
        "\n",
        "da_result = extract_f0(\n",
        "    da_imgs_flt,\n",
        "    half_window_size=half_window_size,\n",
        "    which_quantile=which_quantile,\n",
        "    temporal_smoothing_gaussian_filter_stdev=temporal_smoothing_gaussian_filter_stdev,\n",
        "    temporal_smoothing_gaussian_filter_window_size=temporal_smoothing_gaussian_filter_window_size,\n",
        "    spatial_smoothing_gaussian_filter_stdev=spatial_smoothing_gaussian_filter_stdev,\n",
        "    spatial_smoothing_gaussian_filter_window_size=spatial_smoothing_gaussian_filter_window_size,\n",
        "    bias=bias\n",
        ")\n",
        "\n",
        "# Store denoised data\n",
        "dask_store_zarr(data_basename + postfix_f_f0 + zarr_ext, [\"images\"], [da_result], client)\n",
        "\n",
        "\n",
        "# View results\n",
        "fn = data_basename + postfix_f_f0 + zarr_ext\n",
        "\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "f = zarr.open_group(fn, \"r\")\n",
        "\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(norm_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max], lock=False, compute=False)\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Wavelet Transform\n",
        "\n",
        "* `scale` (`int`): the scale of wavelet transform to apply.\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel).\n",
        "* `block_space` (`int`): extent of each spatial dimension for each block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scale = 3\n",
        "\n",
        "block_frames = 200\n",
        "block_space = 300\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_wt + zarr_ext, client)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "f = zarr.open_group(data_basename + postfix_f_f0 + zarr_ext, \"r\")\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(\n",
        "    imgs, chunks=(block_frames,) + (imgs.ndim - 1) * (block_space,)\n",
        ")\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_result = wavelet_transform(\n",
        "    da_imgs,\n",
        "    scale=scale\n",
        ")\n",
        "\n",
        "# Store denoised data\n",
        "dask_store_zarr(data_basename + postfix_wt + zarr_ext, [\"images\"], [da_result], client)\n",
        "\n",
        "\n",
        "# View results\n",
        "fn = data_basename + postfix_wt + zarr_ext\n",
        "\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "f = zarr.open_group(fn, \"r\")\n",
        "\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(norm_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max], lock=False, compute=False)\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalize Data\n",
        "\n",
        "* `block_frames` (`int`): number of frames to work with in each full frame block (run in parallel).\n",
        "* `block_space` (`int`): extent of each spatial dimension for each block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_frames = 40\n",
        "block_space = 300\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_norm + zarr_ext, client)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "f = zarr.open_group(data_basename + postfix_wt + zarr_ext, \"r\")\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(\n",
        "    imgs, chunks=(block_frames,) + (imgs.ndim - 1) * (block_space,)\n",
        ")\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_flt_mins = da_imgs_flt.min(\n",
        "    axis=tuple(irange(1, da_imgs_flt.ndim)),\n",
        "    keepdims=True\n",
        ")\n",
        "\n",
        "da_imgs_flt_shift = da_imgs_flt - da_imgs_flt_mins\n",
        "\n",
        "da_result = renormalized_images(da_imgs_flt_shift)\n",
        "\n",
        "# Store denoised data\n",
        "dask_store_zarr(data_basename + postfix_norm + zarr_ext, [\"images\"], [da_result], client)\n",
        "\n",
        "\n",
        "# View results\n",
        "fn = data_basename + postfix_norm + zarr_ext\n",
        "\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "f = zarr.open_group(fn, \"r\")\n",
        "\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(norm_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max], lock=False, compute=False)\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dictionary Learning\n",
        "\n",
        "* `n_components` (`int`): number of basis images in the dictionary.\n",
        "* `batchsize` (`int`): minibatch size to use.\n",
        "* `iters` (`int`): number of iterations to run before getting dictionary.\n",
        "* `lambda1` (`float`): weight for L<sup>1</sup> sparisty enforcement on sparse code.\n",
        "* `lambda2` (`float`): weight for L<sup>2</sup> sparisty enforcement on sparse code.\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each full frame block (run in parallel).\n",
        "* `norm_frames` (`int`): number of frames for use during normalization of each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "n_components = 50\n",
        "batchsize = 256\n",
        "iters = 100\n",
        "lambda1 = 0.2\n",
        "lambda2 = 0.0\n",
        "\n",
        "block_frames = 51\n",
        "norm_frames = 100\n",
        "\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_dict + zarr_ext, client)\n",
        "\n",
        "\n",
        "f1 = zarr.open_group(data_basename + postfix_norm + zarr_ext, \"r\")\n",
        "imgs = f1[\"images\"]\n",
        "block_shape = (block_frames,) + imgs.shape[1:]\n",
        "da_imgs = da.from_array(imgs, chunks=block_shape)\n",
        "with open_zarr(data_basename + postfix_dict + zarr_ext, \"w\") as f2:\n",
        "    new_result = f2.create_dataset(\"images\", shape=(n_components,) + da_imgs.shape[1:], dtype=da_imgs.dtype, chunks=True)\n",
        "\n",
        "    result = halo_block_generate_dictionary_parallel(client, None)(generate_dictionary)(block_shape)(\n",
        "        da_imgs,\n",
        "        n_components=n_components,\n",
        "        out=new_result,\n",
        "        **{\"sklearn.decomposition.dict_learning_online\" : {\n",
        "                \"n_jobs\" : 1,\n",
        "                \"n_iter\" : iters,\n",
        "                \"batch_size\" : batchsize,\n",
        "                \"alpha\" : lambda1\n",
        "            }\n",
        "        }\n",
        "    )\n",
        "\n",
        "\n",
        "# View results\n",
        "fn = data_basename + postfix_dict + zarr_ext\n",
        "\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "f = zarr.open_group(fn, \"r\")\n",
        "\n",
        "imgs = f[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(norm_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max], lock=False, compute=False)\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Postprocessing\n",
        "\n",
        "* `significance_threshold` (`float`): number of standard deviations below which to include in \"noise\" estimate\n",
        "* `wavelet_scale` (`int`): scale of wavelet transform to apply (should be the same as the one used above)\n",
        "* `noise_threshold` (`float`): number of units of \"noise\" above which something needs to be to be significant\n",
        "* `accepted_region_shape_constraints` (`dict`): if ROIs don't match this, reduce the `wavelet_scale` once.\n",
        "* `percentage_pixels_below_max` (`float`): upper bound on ratio of ROI pixels not at max intensity vs. all ROI pixels\n",
        "* `min_local_max_distance` (`float`): minimum allowable euclidean distance between two ROIs maximum intensities\n",
        "* `accepted_neuron_shape_constraints` (`dict`): shape constraints for ROI to be kept.\n",
        "\n",
        "* `alignment_min_threshold` (`float`): similarity measure of the intensity of two ROIs images used for merging.\n",
        "* `overlap_min_threshold` (`float`): similarity measure of the masks of two ROIs used for merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "significance_threshold = 3.0\n",
        "wavelet_scale = 3\n",
        "noise_threshold = 3.0\n",
        "percentage_pixels_below_max = 0.8\n",
        "min_local_max_distance = 16.0\n",
        "\n",
        "alignment_min_threshold = 0.6\n",
        "overlap_min_threshold = 0.6\n",
        "\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_post + zarr_ext, client)\n",
        "\n",
        "\n",
        "f1 = zarr.open_group(data_basename + postfix_dict + zarr_ext, \"r\")\n",
        "imgs = f1[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=((1,) + imgs.shape[1:]))\n",
        "\n",
        "with open_zarr(data_basename + postfix_post + zarr_ext, \"w\") as f2:\n",
        "    result = block_postprocess_data_parallel(client)(da_imgs,\n",
        "                                  **{\n",
        "                                        \"wavelet_denoising\" : {\n",
        "                                            \"estimate_noise\" : {\n",
        "                                                \"significance_threshold\" : significance_threshold\n",
        "                                            },\n",
        "                                            \"wavelet.transform\" : {\n",
        "                                                \"scale\" : wavelet_scale\n",
        "                                            },\n",
        "                                            \"significant_mask\" : {\n",
        "                                                \"noise_threshold\" : noise_threshold\n",
        "                                            },\n",
        "                                            \"accepted_region_shape_constraints\" : {\n",
        "                                                \"major_axis_length\" : {\n",
        "                                                    \"min\" : 0.0,\n",
        "                                                    \"max\" : 25.0\n",
        "                                                }\n",
        "                                            },\n",
        "                                            \"remove_low_intensity_local_maxima\" : {\n",
        "                                                \"percentage_pixels_below_max\" : percentage_pixels_below_max\n",
        "                                            },\n",
        "                                            \"remove_too_close_local_maxima\" : {\n",
        "                                                \"min_local_max_distance\" : min_local_max_distance\n",
        "                                            },\n",
        "                                            \"accepted_neuron_shape_constraints\" : {\n",
        "                                                \"area\" : {\n",
        "                                                    \"min\" : 25,\n",
        "                                                    \"max\" : 600\n",
        "                                                },\n",
        "                                                \"eccentricity\" : {\n",
        "                                                    \"min\" : 0.0,\n",
        "                                                    \"max\" : 0.9\n",
        "                                                }\n",
        "                                            }\n",
        "                                        },\n",
        "                                        \"merge_neuron_sets\" : {\n",
        "                                            \"alignment_min_threshold\" : alignment_min_threshold,\n",
        "                                            \"overlap_min_threshold\" : overlap_min_threshold,\n",
        "                                            \"fuse_neurons\" : {\n",
        "                                                \"fraction_mean_neuron_max_threshold\" : 0.01\n",
        "                                            }\n",
        "                                        }\n",
        "                                  }\n",
        "    )\n",
        "\n",
        "    f2.create_group(\"rois\")\n",
        "    for each_name in result.dtype.names:\n",
        "        f2.require_group(\"rois\").create_dataset(\n",
        "            each_name,\n",
        "            data=result[each_name],\n",
        "            chunks=True\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROI and trace extraction\n",
        "\n",
        "* `block_frames` (`int`): number of frames to work with in each block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_frames = 100\n",
        "\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_rois + zarr_ext, client)\n",
        "dask_io_remove(data_basename + postfix_rois + h5_ext, client)\n",
        "\n",
        "\n",
        "with open_zarr(data_basename + postfix_post + zarr_ext, \"r\") as f1:\n",
        "    roi_masks = f1[\"rois/mask\"]\n",
        "\n",
        "    da_roi_masks = da.from_array(\n",
        "        roi_masks, chunks=(block_frames,) + roi_masks.shape[1:]\n",
        "    )\n",
        "\n",
        "    da_lbls = da.arange(\n",
        "        1,\n",
        "        len(da_roi_masks) + 1,\n",
        "        chunks=da_roi_masks.chunks[0],\n",
        "        dtype=np.uint64\n",
        "    )\n",
        "    da_lblimg = (\n",
        "        da_lbls[(slice(None),) + (da_roi_masks.ndim - 1) * (None,)] * \n",
        "        da_roi_masks.astype(np.uint64)\n",
        "    ).max(axis=0)\n",
        "\n",
        "    dask_store_zarr(\n",
        "        data_basename + postfix_rois + zarr_ext,\n",
        "        [\"masks\", \"masks_j\", \"labels\", \"labels_j\"],\n",
        "        [da_roi_masks, da_roi_masks.astype(numpy.uint8), da_lblimg, da_lblimg.astype(numpy.uint8)],\n",
        "        client\n",
        "    )\n",
        "\n",
        "\n",
        "with h5py.File(data_basename + postfix_rois + h5_ext, \"w\") as f2:\n",
        "    with open_zarr(data_basename + postfix_rois + zarr_ext, \"r\") as f1:\n",
        "        zarr_to_hdf5(f1, f2)\n",
        "\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_traces + zarr_ext, client)\n",
        "dask_io_remove(data_basename + postfix_traces + h5_ext, client)\n",
        "\n",
        "\n",
        "with open_zarr(data_basename + postfix_f_f0 + zarr_ext, \"r\") as fh_f_f0:\n",
        "    with open_zarr(data_basename + postfix_rois + zarr_ext, \"r\") as fh_rois:\n",
        "        # Load and prep data for computation.\n",
        "        images = fh_f_f0[\"images\"]\n",
        "        da_images = da.from_array(\n",
        "            images, chunks=(block_frames,) + images.shape[1:]\n",
        "        )\n",
        "        masks = fh_rois[\"masks\"]\n",
        "        da_masks = da.from_array(\n",
        "            masks, chunks=(block_frames,) + masks.shape[1:]\n",
        "        )\n",
        "\n",
        "        da_result = compute_traces(da_images, da_masks)\n",
        "\n",
        "        # Store traces\n",
        "        dask_store_zarr(data_basename + postfix_traces + zarr_ext, [\"traces\"], [da_result], client)\n",
        "\n",
        "\n",
        "with h5py.File(data_basename + postfix_traces + h5_ext, \"w\") as f2:\n",
        "    with open_zarr(data_basename + postfix_traces + zarr_ext, \"r\") as f1:\n",
        "        zarr_to_hdf5(f1, f2)\n",
        "\n",
        "\n",
        "# View results\n",
        "fn = data_basename + postfix_f_f0 + zarr_ext\n",
        "\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "f1 = zarr.open_group(data_basename + postfix_f_f0 + zarr_ext, \"r\")\n",
        "\n",
        "imgs = f1[\"images\"]\n",
        "da_imgs = da.from_array(imgs, chunks=(block_frames,) + imgs.shape[1:])\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max], lock=False, compute=False)\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")\n",
        "\n",
        "f2 = zarr.open_group(data_basename + postfix_rois + zarr_ext, \"r\")\n",
        "lblimg = f2[\"labels\"][...]\n",
        "lblimg_msk = numpy.ma.masked_array(lblimg, mask=(lblimg==0))\n",
        "\n",
        "mplsv.viewer.matshow(lblimg_msk, alpha=0.3, cmap=mpl.cm.jet)\n",
        "\n",
        "\n",
        "mskimg = None\n",
        "mskimg_j = None\n",
        "lblimg = None\n",
        "traces = None\n",
        "traces_j = None\n",
        "\n",
        "del mskimg\n",
        "del mskimg_j\n",
        "del lblimg\n",
        "del traces\n",
        "del traces_j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End of workflow. Shutdown cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import distributed\n",
        "from nanshe_workflow.par import shutdown_distributed\n",
        "\n",
        "shutdown_distributed(distributed.client.default_client())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare interactive projection graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "import textwrap\n",
        "import zlib\n",
        "\n",
        "import numpy\n",
        "import numpy as np\n",
        "\n",
        "import bokeh.plotting\n",
        "import bokeh.plotting as bp\n",
        "\n",
        "import bokeh.io\n",
        "import bokeh.io as bio\n",
        "\n",
        "import bokeh.embed\n",
        "import bokeh.embed as be\n",
        "\n",
        "from bokeh.models.mappers import LinearColorMapper\n",
        "\n",
        "import webcolors\n",
        "\n",
        "from bokeh.models import CustomJS, ColumnDataSource, HoverTool\n",
        "from bokeh.models.layouts import Row\n",
        "\n",
        "from builtins import (\n",
        "    map as imap,\n",
        "    range as irange\n",
        ")\n",
        "\n",
        "from past.builtins import basestring\n",
        "\n",
        "import nanshe_workflow\n",
        "from nanshe_workflow.data import io_remove, open_zarr\n",
        "from nanshe_workflow.vis import get_rgb_array, get_rgba_array, get_all_greys, masks_to_contours_2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open_zarr(data_basename + postfix_rois + zarr_ext, \"r\") as f:\n",
        "    mskimg = f[\"masks\"][...]\n",
        "\n",
        "with open_zarr(data_basename + postfix_traces + zarr_ext, \"r\") as f:\n",
        "    traces = f[\"traces\"][...]\n",
        "\n",
        "with open_zarr(data_basename + postfix_proj + zarr_ext, \"r\") as f:\n",
        "    imgproj_mean = f[\"mean\"][...]\n",
        "    imgproj_max = f[\"max\"][...]\n",
        "    imgproj_std = f[\"std\"][...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result visualization\n",
        "\n",
        "* `proj_img` (`str` or `list` of `str`): which projection or projections to plot (e.g. \"max\", \"mean\", \"std\").\n",
        "* `block_size` (`int`): size of each point on any dimension in the image in terms of pixels.\n",
        "* `roi_alpha` (`float`): transparency of the ROIs in a range of [0.0, 1.0].\n",
        "* `roi_border_width` (`int`): width of the line border on each ROI.\n",
        "\n",
        "<br>\n",
        "* `trace_plot_width` (`int`): width of the trace plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "proj_img = \"std\"\n",
        "block_size = 1\n",
        "roi_alpha = 0.3\n",
        "roi_border_width = 3\n",
        "trace_plot_width = 500\n",
        "\n",
        "\n",
        "bio.curdoc().clear()\n",
        "\n",
        "grey_range = get_all_greys()\n",
        "grey_cm = LinearColorMapper(grey_range)\n",
        "\n",
        "colors_rgb = get_rgb_array(len(mskimg))\n",
        "colors_rgb = colors_rgb.tolist()\n",
        "colors_rgb = list(imap(webcolors.rgb_to_hex, colors_rgb))\n",
        "\n",
        "mskctr_pts_y, mskctr_pts_x = masks_to_contours_2d(mskimg)\n",
        "\n",
        "mskctr_pts_dtype = np.min_scalar_type(max(mskimg.shape[1:]) - 1)\n",
        "mskctr_pts_y = [np.array(_, dtype=mskctr_pts_dtype) for _ in mskctr_pts_y]\n",
        "mskctr_pts_x = [np.array(_, dtype=mskctr_pts_dtype) for _ in mskctr_pts_x]\n",
        "\n",
        "mskctr_srcs = ColumnDataSource(data=dict(x=mskctr_pts_x, y=mskctr_pts_y, color=colors_rgb))\n",
        "\n",
        "\n",
        "if isinstance(proj_img, basestring):\n",
        "    proj_img = [proj_img]\n",
        "else:\n",
        "    proj_img = list(proj_img)\n",
        "\n",
        "\n",
        "proj_plot_width = block_size*mskimg.shape[2]\n",
        "proj_plot_height = block_size*mskimg.shape[1]\n",
        "plot_projs = []\n",
        "\n",
        "if \"max\" in proj_img:\n",
        "    plot_max = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Max Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_max.image(image=[numpy.flipud(imgproj_max)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[imgproj_max.shape[1]], dh=[imgproj_max.shape[0]], color_mapper=grey_cm)\n",
        "    plot_max.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_max.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_max.axis)):\n",
        "        plot_max.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_max)\n",
        "\n",
        "\n",
        "if \"mean\" in proj_img:\n",
        "    plot_mean = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Mean Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_mean.image(image=[numpy.flipud(imgproj_mean)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[mskimg.shape[2]], dh=[mskimg.shape[1]], color_mapper=grey_cm)\n",
        "    plot_mean.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_mean.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_mean.axis)):\n",
        "        plot_mean.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_mean)\n",
        "\n",
        "\n",
        "if \"std\" in proj_img:\n",
        "    plot_std = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Std Dev Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_std.image(image=[numpy.flipud(imgproj_std)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[mskimg.shape[2]], dh=[mskimg.shape[1]], color_mapper=grey_cm)\n",
        "    plot_std.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_std.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_std.axis)):\n",
        "        plot_std.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_std)\n",
        "\n",
        "\n",
        "all_tr_dtype_srcs = ColumnDataSource(data=dict(traces_dtype=traces.dtype.type(0)[None]))\n",
        "all_tr_shape_srcs = ColumnDataSource(data=dict(traces_shape=traces.shape))\n",
        "all_tr_srcs = ColumnDataSource(data=dict(\n",
        "    traces=numpy.frombuffer(\n",
        "        zlib.compress(traces.tobytes()),\n",
        "        dtype=np.uint8\n",
        "    )\n",
        "))\n",
        "tr_srcs = ColumnDataSource(data=dict(times_sel=[], traces_sel=[], colors_sel=[]))\n",
        "plot_tr = bp.Figure(plot_width=trace_plot_width, plot_height=proj_plot_height,\n",
        "                    x_range=(0.0, float(traces.shape[1])), y_range=(float(traces.min()), float(traces.max())),\n",
        "                    tools=[\"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"], title=\"ROI traces\",\n",
        "                    background_fill_color=\"black\", border_fill_color=\"black\")\n",
        "plot_tr.multi_line(\"times_sel\", \"traces_sel\", source=tr_srcs, color=\"colors_sel\")\n",
        "\n",
        "plot_tr.outline_line_color = \"white\"\n",
        "for i in irange(len(plot_tr.axis)):\n",
        "    plot_tr.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "plot_projs.append(plot_tr)\n",
        "\n",
        "\n",
        "mskctr_srcs.callback = CustomJS(\n",
        "    args=dict(\n",
        "        all_tr_dtype_srcs=all_tr_dtype_srcs,\n",
        "        all_tr_shape_srcs=all_tr_shape_srcs,\n",
        "        all_tr_srcs=all_tr_srcs,\n",
        "        tr_srcs=tr_srcs\n",
        "    ), code=\"\"\"\n",
        "    var range = function(n){ return Array.from(Array(n).keys()); };\n",
        "\n",
        "    var traces_not_decoded = (all_tr_dtype_srcs.get('data')['traces_dtype'] == 0);\n",
        "    var traces_dtype = all_tr_dtype_srcs.get('data')['traces_dtype'].constructor;\n",
        "    var traces_shape = all_tr_shape_srcs.get('data')['traces_shape'];\n",
        "    var trace_len = traces_shape[1];\n",
        "    var traces = all_tr_srcs.get('data')['traces'];\n",
        "    if (traces_not_decoded) {\n",
        "        traces = window.pako.inflate(traces);\n",
        "        traces = new traces_dtype(traces.buffer);\n",
        "        all_tr_srcs.get('data')['traces'] = traces;\n",
        "        all_tr_dtype_srcs.get('data')['traces_dtype'] = 1;\n",
        "    }\n",
        "\n",
        "    var inds = cb_obj.get('selected')['1d'].indices;\n",
        "    var colors = cb_obj.get('data')['color'];\n",
        "    var selected = tr_srcs.get('data');\n",
        "\n",
        "    var times = range(trace_len);\n",
        "\n",
        "    selected['times_sel'] = [];\n",
        "    selected['traces_sel'] = [];\n",
        "    selected['colors_sel'] = [];\n",
        "\n",
        "    for (i = 0; i < inds.length; i++) {\n",
        "        var inds_i = inds[i];\n",
        "        var trace_i = traces.slice(trace_len*inds_i, trace_len*(inds_i+1));\n",
        "        var color_i = colors[inds_i];\n",
        "\n",
        "        selected['times_sel'].push(times);\n",
        "        selected['traces_sel'].push(trace_i);\n",
        "        selected['colors_sel'].push(color_i);\n",
        "    }\n",
        "\n",
        "    tr_srcs.trigger('change');\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "plot_group = Row(*plot_projs)\n",
        "\n",
        "\n",
        "# Clear out the old HTML file before writing a new one.\n",
        "io_remove(data_basename + postfix_html + html_ext)\n",
        "\n",
        "\n",
        "def indent(text, spaces):\n",
        "    spaces = \" \" * int(spaces)\n",
        "    return \"\\n\".join(imap(lambda l: spaces + l, text.splitlines()))\n",
        "\n",
        "def write_html(filename, title, div, script, cdn):\n",
        "    html_tmplt = textwrap.dedent(u\"\"\"\\\n",
        "        <html lang=\"en\">\n",
        "            <head>\n",
        "                <meta charset=\"utf-8\">\n",
        "                <title>{title}</title>\n",
        "                {cdn}\n",
        "                <style>\n",
        "                  html {{\n",
        "                    width: 100%;\n",
        "                    height: 100%;\n",
        "                  }}\n",
        "                  body {{\n",
        "                    width: 90%;\n",
        "                    height: 100%;\n",
        "                    margin: auto;\n",
        "                    background-color: black;\n",
        "                  }}\n",
        "                </style>\n",
        "            </head>\n",
        "            <body>\n",
        "                {div}\n",
        "                {script}\n",
        "            </body>\n",
        "        </html>\n",
        "    \"\"\")\n",
        "\n",
        "    html_cont = html_tmplt.format(\n",
        "        title=title,\n",
        "        div=indent(div, 8),\n",
        "        script=indent(script, 8),\n",
        "        cdn=indent(cdn, 8),\n",
        "    )\n",
        "\n",
        "    with io.open(filename, \"w\") as fh:\n",
        "        fh.write(html_cont)\n",
        "\n",
        "script, div = be.components(plot_group)\n",
        "cdn = bokeh.resources.CDN.render() + \"\\n\"\n",
        "cdn += \"\"\"\n",
        "<script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/pako/1.0.4/pako_inflate.min.js\"></script>\n",
        "\"\"\"\n",
        "cdn += \"\\n\"\n",
        "\n",
        "write_html(data_basename + postfix_html + html_ext, data_basename + postfix_html, div, script, cdn)\n",
        "\n",
        "\n",
        "from IPython.display import display, IFrame\n",
        "display(IFrame(data_basename + postfix_html + html_ext, \"100%\", 1.05*proj_plot_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test teardown. Ignore warnings during production runs.\n",
        "\n",
        "%run ./teardown_tests.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    },
    "widgets": {
      "state": {},
      "version": "1.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
