{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test setup. Ignore warnings during production runs.\n",
        "\n",
        "%run ./setup_tests.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Specify input data\n",
        "\n",
        "* `data_dir` (`str`): Where the data is located. (change if data is not in the current directory, normally is)\n",
        "* `data` (`str`): HDF5 file to use as input data.\n",
        "* `data_basename` (`str`): Basename to use for intermediate and final result files.\n",
        "* `dataset` (`str`): HDF5 dataset to use as input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"\"\n",
        "data = \"data.tif\"\n",
        "data_basename = \"data\"\n",
        "dataset = \"images\"\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "data_ext = os.path.splitext(data)[1].lower()\n",
        "data_dir = os.path.abspath(data_dir)\n",
        "\n",
        "subgroup_raw = \"raw\"\n",
        "subgroup_trim = \"trim\"\n",
        "subgroup_dn = \"dn\"\n",
        "subgroup_reg = \"reg\"\n",
        "subgroup_reg_images = \"reg/images\"\n",
        "subgroup_reg_shifts = \"reg/shifts\"\n",
        "subgroup_sub = \"sub\"\n",
        "subgroup_norm = \"norm\"\n",
        "subgroup_dict = \"dict\"\n",
        "subgroup_post = \"post\"\n",
        "subgroup_post_mask = \"post/mask\"\n",
        "subgroup_rois = \"rois\"\n",
        "subgroup_rois_masks = \"rois/masks\"\n",
        "subgroup_rois_masks_j = \"rois/masks_j\"\n",
        "subgroup_rois_labels = \"rois/labels\"\n",
        "subgroup_rois_labels_j = \"rois/labels_j\"\n",
        "subgroup_traces = \"traces\"\n",
        "subgroup_proj = \"proj\"\n",
        "subgroup_proj_hmean = \"proj/hmean\"\n",
        "subgroup_proj_max = \"proj/max\"\n",
        "subgroup_proj_mean = \"proj/mean\"\n",
        "subgroup_proj_std = \"proj/std\"\n",
        "\n",
        "postfix_rois = \"_rois\"\n",
        "postfix_traces = \"_traces\"\n",
        "postfix_html = \"_proj\"\n",
        "\n",
        "h5_ext = os.path.extsep + \"h5\"\n",
        "tiff_ext = os.path.extsep + \"tif\"\n",
        "zarr_ext = os.path.extsep + \"zarr\"\n",
        "html_ext = os.path.extsep + \"html\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from psutil import cpu_count\n",
        "\n",
        "cluster_kwargs = {\n",
        "    \"ip\": \"\"\n",
        "}\n",
        "client_kwargs = {}\n",
        "adaptive_kwargs = {\n",
        "    \"minimum\": 0,\n",
        "    \"maximum\": int(os.environ.get(\"CORES\", cpu_count())) - 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zarr\n",
        "\n",
        "from nanshe_workflow.data import DistributedDirectoryStore\n",
        "\n",
        "zarr_store = zarr.open_group(DistributedDirectoryStore(data_basename + zarr_ext), \"a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure and startup Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.par import startup_distributed\n",
        "from nanshe_workflow.data import DistributedArrayStore\n",
        "\n",
        "client = startup_distributed(0, cluster_kwargs, client_kwargs, adaptive_kwargs)\n",
        "\n",
        "dask_store = DistributedArrayStore(zarr_store, client=client)\n",
        "\n",
        "client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define functions for computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.cm\n",
        "import matplotlib.pyplot\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mplview.core import MatplotlibViewer as MPLViewer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import logging\n",
        "import os\n",
        "import sys\n",
        "\n",
        "from builtins import range as irange\n",
        "\n",
        "try:\n",
        "    from contextlib import suppress\n",
        "except ImportError:\n",
        "    from contextlib2 import suppress\n",
        "\n",
        "import numpy\n",
        "import scipy\n",
        "import scipy.ndimage\n",
        "import h5py\n",
        "\n",
        "import numpy as np\n",
        "import scipy as sp\n",
        "import scipy.ndimage as spim\n",
        "import h5py as hp\n",
        "\n",
        "import dask\n",
        "import dask.array\n",
        "import dask.array.fft\n",
        "import dask.distributed\n",
        "\n",
        "import dask.array as da\n",
        "\n",
        "import dask_imread\n",
        "import dask_ndfilters\n",
        "import dask_ndfourier\n",
        "\n",
        "import zarr\n",
        "\n",
        "import nanshe\n",
        "from nanshe.imp.segment import generate_dictionary\n",
        "\n",
        "import nanshe_workflow\n",
        "from nanshe_workflow.data import io_remove, dask_io_remove, dask_load_hdf5, dask_store_zarr, zip_zarr, open_zarr\n",
        "\n",
        "zarr.blosc.set_nthreads(1)\n",
        "zarr.blosc.use_threads = False\n",
        "client.run(zarr.blosc.set_nthreads, 1)\n",
        "client.run(setattr, zarr.blosc, \"use_threads\", False)\n",
        "\n",
        "logging.getLogger(\"nanshe\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.data import DistributedDirectoryStore\n",
        "from nanshe_workflow.data import hdf5_to_zarr, zarr_to_hdf5\n",
        "from nanshe_workflow.data import save_tiff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import pyfftw.interfaces.numpy_fft as numpy_fft\n",
        "except ImportError:\n",
        "    import numpy.fft as numpy_fft\n",
        "\n",
        "rfftn = da.fft.fft_wrap(numpy_fft.rfftn)\n",
        "irfftn = da.fft.fft_wrap(numpy_fft.irfftn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.imp2 import extract_f0, wavelet_transform, renormalized_images, normalize_data\n",
        "\n",
        "from nanshe_workflow.par import halo_block_generate_dictionary_parallel\n",
        "from nanshe_workflow.imp import block_postprocess_data_parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.proj2 import compute_traces\n",
        "\n",
        "from nanshe_workflow.proj2 import compute_adj_harmonic_mean_projection\n",
        "\n",
        "from nanshe_workflow.proj2 import norm_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Begin workflow. Set parameters and run each cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert TIFF/HDF5 to Zarr\n",
        "\n",
        "* `block_chunks` (`tuple` of `int`s): chunk size for each block loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_chunks = (100, -1, -1)\n",
        "\n",
        "for k in [subgroup_raw]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "if data_ext == tiff_ext:\n",
        "    dask_store[subgroup_raw] = dask_imread.imread(data, nframes=block_chunks[0])\n",
        "elif data_ext == h5_ext:\n",
        "    dask_store[subgroup_raw] = dask_load_hdf5(data, dataset, chunks=block_chunks)\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_raw], notebook=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_raw]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Trimming\n",
        "\n",
        "* `front` (`int`): amount to trim off the front\n",
        "* `back` (`int`): amount to trim off the back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "front = 0\n",
        "back = 0\n",
        "\n",
        "\n",
        "for k in [subgroup_trim]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_raw]\n",
        "\n",
        "# Trim frames from front and back\n",
        "da_imgs_trim = da_imgs[front:len(da_imgs)-back]\n",
        "\n",
        "# Store trimmed data\n",
        "dask_store[subgroup_trim] = da_imgs_trim\n",
        "\n",
        "# Check progress of store step\n",
        "dask.distributed.progress(dask_store[subgroup_trim], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_trim]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Denoising\n",
        "\n",
        "* `med_filt_size` (`int`): footprint size for median filter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "med_filt_size = 10\n",
        "\n",
        "\n",
        "for k in [subgroup_dn]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_trim]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "# Median filter frames\n",
        "da_imgs_filt = dask_ndfilters.median_filter(\n",
        "    da_imgs_flt, (1,) + (da_imgs_flt.ndim - 1) * (med_filt_size,)\n",
        ")\n",
        "\n",
        "# Reset minimum to original value.\n",
        "da_imgs_filt += da_imgs.min() - da_imgs_filt.min()\n",
        "\n",
        "# Store denoised data\n",
        "dask.distributed.fire_and_forget(dask.persist(da_imgs.min(), da_imgs_filt, da_imgs_filt.min()))\n",
        "dask_store[subgroup_dn] = da_imgs_filt\n",
        "\n",
        "# Check progress of store step\n",
        "dask.distributed.progress(dask_store[subgroup_dn], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_dn]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Registration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def fourier_shift_wrap(array, shift):\n",
        "    result = numpy.empty_like(array)\n",
        "    for i in irange(len(array)):\n",
        "        result[i] = spim.fourier_shift(array[i], shift[0][i])\n",
        "    return result\n",
        "\n",
        "\n",
        "def find_best_match(matches):\n",
        "    best_match = numpy.zeros(\n",
        "        matches.shape[:1],\n",
        "        dtype=matches.dtype\n",
        "    )\n",
        "    if matches.size:\n",
        "        i = numpy.argmin((matches ** 2).sum(axis=0))\n",
        "        best_match = matches[:, i]\n",
        "\n",
        "    return best_match\n",
        "\n",
        "\n",
        "def compute_offset(match_mask):\n",
        "    match_mask = match_mask[0][0]\n",
        "\n",
        "    result = numpy.empty((len(match_mask), match_mask.ndim - 1), dtype=int)\n",
        "    for i in irange(len(match_mask)):\n",
        "        match_mask_i = match_mask[i]\n",
        "\n",
        "        frame_shape = np.array(match_mask_i.shape)\n",
        "        half_frame_shape = frame_shape // 2\n",
        "\n",
        "        matches = np.array(match_mask_i.nonzero())\n",
        "        above = (matches > half_frame_shape[:, None]).astype(matches.dtype)\n",
        "        matches -= above * frame_shape[:, None]\n",
        "\n",
        "        result[i] = find_best_match(matches)\n",
        "\n",
        "    return result\n",
        "\n",
        "\n",
        "def roll_frames_chunk(frames, shifts):\n",
        "    # Needed as Dask shares objects and we plan to write to it.\n",
        "    # Also if there is only one refcount the old object is freed.\n",
        "    frames = numpy.copy(frames)\n",
        "\n",
        "    for i in irange(len(frames)):\n",
        "        frames[i] = numpy.roll(\n",
        "            frames[i],\n",
        "            tuple(shifts[i]),\n",
        "            axis=tuple(irange(frames.ndim - 1))\n",
        "        )\n",
        "\n",
        "    return frames\n",
        "\n",
        "\n",
        "def roll_frames(frames, shifts):\n",
        "    frames = frames.rechunk({\n",
        "        k: v for k, v in enumerate(frames.shape[1:], 1)\n",
        "    })\n",
        "    shifts = shifts.rechunk({1: shifts.shape[1]})\n",
        "\n",
        "    rolled_frames = da.atop(\n",
        "        roll_frames_chunk, tuple(irange(frames.ndim)),\n",
        "        frames, tuple(irange(frames.ndim)),\n",
        "        shifts, (0, frames.ndim),\n",
        "        dtype=da_imgs.dtype,\n",
        "        concatenate=True\n",
        "    )\n",
        "\n",
        "    return rolled_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_reps = 5\n",
        "tmpl_hist_wght = 0.25\n",
        "thld_rel_dist = 0.0\n",
        "\n",
        "\n",
        "for k in [subgroup_reg_images, subgroup_reg_shifts]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_reg]\n",
        "zarr_store.require_group(subgroup_reg)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_dn]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "# Create frame shape arrays\n",
        "frame_shape = np.array(da_imgs_flt.shape[1:], dtype=int)\n",
        "half_frame_shape = frame_shape // 2\n",
        "frame_shape = da.asarray(frame_shape)\n",
        "half_frame_shape = da.asarray(half_frame_shape)\n",
        "\n",
        "# Find the inverse of each frame\n",
        "da_imgs_flt_min = da_imgs_flt.min()\n",
        "da_imgs_inv = dask.array.reciprocal(da_imgs_flt - (da_imgs_flt_min - 1))\n",
        "\n",
        "# Compute the FFT of inverse frames and template\n",
        "da_imgs_fft = rfftn(da_imgs_inv, axes=tuple(irange(1, da_imgs_flt.ndim)))\n",
        "da_imgs_fft_tmplt = da_imgs_fft.mean(axis=0, keepdims=True)\n",
        "\n",
        "# Initialize\n",
        "i = 0\n",
        "avg_rel_dist = 1.0\n",
        "tmpl_hist_wght = da_imgs_flt.dtype.type(tmpl_hist_wght)\n",
        "da_shifts = da.zeros(\n",
        "    (len(da_imgs_flt), da_imgs_flt.ndim - 1),\n",
        "    dtype=int,\n",
        "    chunks=(1, da_imgs_flt.ndim - 1)\n",
        ")\n",
        "\n",
        "# Persist FFT of frames and template\n",
        "da_imgs_flt_min, da_imgs_fft, da_imgs_fft_tmplt = client.persist([\n",
        "    da_imgs_flt_min, da_imgs_fft, da_imgs_fft_tmplt\n",
        "])\n",
        "dask.distributed.fire_and_forget(da_imgs_flt_min)\n",
        "del da_imgs_flt_min\n",
        "\n",
        "while avg_rel_dist > thld_rel_dist and i < num_reps:\n",
        "    # Compute the shifted frames\n",
        "    da_shifted_frames = da.atop(\n",
        "        fourier_shift_wrap,\n",
        "        (0,) + tuple(irange(1, da_imgs_fft.ndim)),\n",
        "        da_imgs_fft,\n",
        "        (0,) + tuple(irange(1, da_imgs_fft.ndim)),\n",
        "        da_shifts,\n",
        "        (0, da_imgs_fft.ndim),\n",
        "        dtype=da_imgs_fft.dtype\n",
        "    )\n",
        "\n",
        "    # Compute the template FFT\n",
        "    da_imgs_fft_tmplt = (\n",
        "        tmpl_hist_wght * da_imgs_fft_tmplt +\n",
        "        (1 - tmpl_hist_wght) * da_shifted_frames.mean(axis=0, keepdims=True)\n",
        "    )\n",
        "\n",
        "    # Free connected persisted values\n",
        "    del da_shifted_frames\n",
        "\n",
        "    # Find the best overlap with the template.\n",
        "    da_overlap = irfftn(\n",
        "        da_imgs_fft * da_imgs_fft_tmplt,\n",
        "        s=da_imgs_flt.shape[1:],\n",
        "        axes=tuple(irange(1, da_imgs_flt.ndim))\n",
        "    )\n",
        "    da_overlap_max = da_overlap.max(axis=tuple(irange(1, da_imgs_flt.ndim)), keepdims=True)\n",
        "    da_overlap_max_match = (da_overlap == da_overlap_max)\n",
        "\n",
        "    # Compute the shift for each frame.\n",
        "    old_da_shifts = da_shifts\n",
        "    da_shifts = da.atop(\n",
        "        compute_offset,\n",
        "        (0, da_overlap_max_match.ndim),\n",
        "        da_overlap_max_match.rechunk(dict(enumerate(da_overlap_max_match.shape[1:], 1))),\n",
        "        tuple(irange(0, da_overlap_max_match.ndim)),\n",
        "        dtype=int,\n",
        "        new_axes={da_overlap_max_match.ndim: da_overlap_max_match.ndim - 1}\n",
        "    )\n",
        "\n",
        "    # Free connected persisted values\n",
        "    del da_overlap\n",
        "    del da_overlap_max\n",
        "    del da_overlap_max_match\n",
        "\n",
        "    # Remove any collective frame drift.\n",
        "    da_drift = da_shifts.mean(axis=0, keepdims=True).round().astype(da_shifts.dtype)\n",
        "    da_shifts = da_shifts - da_drift\n",
        "\n",
        "    # Free connected persisted values\n",
        "    del da_drift\n",
        "\n",
        "    # Find shift change.\n",
        "    diff_da_shifts = da_shifts - old_da_shifts\n",
        "    rel_diff_da_shifts = (\n",
        "        diff_da_shifts.astype(da_imgs_flt.dtype) / \n",
        "        frame_shape.astype(da_imgs_flt.dtype) /\n",
        "        (da_imgs_flt.dtype.type(len(frame_shape)) ** 0.5)\n",
        "    )\n",
        "    rel_dist_da_shifts = (rel_diff_da_shifts ** 2.0).sum(axis=1) ** 0.5\n",
        "    avg_rel_dist = rel_dist_da_shifts.sum() / da_imgs_flt.dtype.type(len(da_shifts))\n",
        "\n",
        "    # Free old shifts\n",
        "    del old_da_shifts\n",
        "\n",
        "    # Free connected persisted values\n",
        "    del diff_da_shifts\n",
        "    del rel_diff_da_shifts\n",
        "    del rel_dist_da_shifts\n",
        "\n",
        "    # Persist values needed for the next iteration (and end of this one).\n",
        "    da_imgs_fft_tmplt, da_shifts, avg_rel_dist = client.persist([da_imgs_fft_tmplt, da_shifts, avg_rel_dist])\n",
        "    dask.distributed.fire_and_forget(da_shifts)\n",
        "\n",
        "    # Compute change\n",
        "    dask.distributed.progress(avg_rel_dist, notebook=False)\n",
        "    print(\"\")\n",
        "    avg_rel_dist = avg_rel_dist.compute()\n",
        "    i += 1\n",
        "\n",
        "    # Show change\n",
        "    print((i, avg_rel_dist))\n",
        "\n",
        "# Drop unneeded items\n",
        "del frame_shape\n",
        "del half_frame_shape\n",
        "del da_imgs_flt\n",
        "del da_imgs_inv\n",
        "del da_imgs_fft\n",
        "del da_imgs_fft_tmplt\n",
        "\n",
        "# Roll all parts to clip to one side\n",
        "# Keep origin static\n",
        "da_imgs_shifted = roll_frames(\n",
        "    da_imgs,\n",
        "    da.clip(da_shifts, None, 0)\n",
        ")\n",
        "\n",
        "# Truncate all frames to smallest one\n",
        "da_imgs_trunc_shape = da.asarray(da_imgs.shape[1:]) - abs(da_shifts).max(axis=0)\n",
        "da_imgs_trunc_shape = da_imgs_trunc_shape.compute()\n",
        "\n",
        "da_imgs_trunc_cut = tuple(map(\n",
        "    lambda s: slice(None, s), da_imgs_trunc_shape\n",
        "))\n",
        "\n",
        "da_imgs_trunc = da_imgs_shifted[(slice(None),) + da_imgs_trunc_cut]\n",
        "\n",
        "# Free raw data\n",
        "del da_imgs\n",
        "\n",
        "# Store registered data\n",
        "dask_store.update({\n",
        "    subgroup_reg_images: da_imgs_trunc,\n",
        "    subgroup_reg_shifts: da_shifts,\n",
        "})\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[subgroup_reg_images],\n",
        "        dask_store[subgroup_reg_shifts]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")\n",
        "\n",
        "# Free truncated frames and shifts\n",
        "del da_imgs_trunc\n",
        "del da_shifts\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_reg_images]\n",
        "da_shifts = dask_store[subgroup_reg_shifts]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "fig, axs = plt.subplots(nrows=da_shifts.shape[1], sharex=True)\n",
        "fig.subplots_adjust(hspace=0.0)\n",
        "for i in range(da_shifts.shape[1]):\n",
        "    axs[i].plot(np.asarray(da_shifts[:, i]))\n",
        "    axs[i].set_ylabel(\"%s (px)\" % chr(ord(\"X\") + da_shifts.shape[1] - i - 1))\n",
        "    axs[i].yaxis.set_tick_params(width=1.5)\n",
        "    [v.set_linewidth(2) for v in axs[i].spines.values()]\n",
        "axs[-1].set_xlabel(\"Frame (#)\")\n",
        "axs[-1].set_xlim((0, da_shifts.shape[0] - 1))\n",
        "axs[-1].xaxis.set_tick_params(width=1.5)\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Projections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_proj_hmean, subgroup_proj_max, subgroup_proj_mean, subgroup_proj_std]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_proj]\n",
        "zarr_store.require_group(subgroup_proj)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_reg_images]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_proj_hmean = compute_adj_harmonic_mean_projection(da_imgs_flt)\n",
        "\n",
        "da_imgs_proj_max = da_imgs_flt.max(axis=0)\n",
        "\n",
        "da_imgs_proj_mean, da_imgs_proj_std = da_imgs_flt.mean(axis=0), da_imgs_flt.std(axis=0)\n",
        "\n",
        "# Store projections\n",
        "dask_store.update(dict(zip(\n",
        "    [subgroup_proj_hmean, subgroup_proj_max, subgroup_proj_mean, subgroup_proj_std],\n",
        "    [da_imgs_proj_hmean, da_imgs_proj_max, da_imgs_proj_mean, da_imgs_proj_std]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[subgroup_proj_hmean],\n",
        "        dask_store[subgroup_proj_max],\n",
        "        dask_store[subgroup_proj_mean],\n",
        "        dask_store[subgroup_proj_std]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtract Projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_sub]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_reg_images]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_sub = da_imgs_flt - compute_adj_harmonic_mean_projection(da_imgs_flt)\n",
        "da_imgs_sub -= da_imgs_sub.min()\n",
        "\n",
        "# Store background removed data\n",
        "dask_store[subgroup_sub] = da_imgs_sub\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_sub], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_sub]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_norm]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_sub]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_flt_mins = da_imgs_flt.min(\n",
        "    axis=tuple(irange(1, da_imgs_flt.ndim)),\n",
        "    keepdims=True\n",
        ")\n",
        "\n",
        "da_imgs_flt_shift = da_imgs_flt - da_imgs_flt_mins\n",
        "\n",
        "da_result = renormalized_images(da_imgs_flt_shift)\n",
        "\n",
        "# Store normalized data\n",
        "dask_store[subgroup_norm] = da_result\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_norm], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_norm]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dictionary Learning\n",
        "\n",
        "* `n_components` (`int`): number of basis images in the dictionary.\n",
        "* `batchsize` (`int`): minibatch size to use.\n",
        "* `iters` (`int`): number of iterations to run before getting dictionary.\n",
        "* `lambda1` (`float`): weight for L<sup>1</sup> sparisty enforcement on sparse code.\n",
        "* `lambda2` (`float`): weight for L<sup>2</sup> sparisty enforcement on sparse code.\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dask_ml\n",
        "import dask_ml.base\n",
        "import sklearn\n",
        "import sklearn.decomposition\n",
        "\n",
        "class MiniBatchDictionaryLearning(dask_ml.base._BigPartialFitMixin,\n",
        "                                  sklearn.decomposition.MiniBatchDictionaryLearning):\n",
        "    pass\n",
        "\n",
        "\n",
        "n_components = 5\n",
        "batchsize = 256\n",
        "iters = 100\n",
        "lambda1 = 0.001\n",
        "lambda2 = 0.0\n",
        "\n",
        "block_frames = 51\n",
        "\n",
        "\n",
        "for k in [subgroup_dict]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "da_imgs = dask_store[subgroup_norm]\n",
        "da_imgs_mtx = da_imgs.reshape(\n",
        "    da_imgs.shape[0],\n",
        "    int(np.prod(da_imgs.shape[1:]))\n",
        ")\n",
        "\n",
        "dict_sel_idx = []\n",
        "for i in range(n_components):\n",
        "    redraw = True\n",
        "    while redraw:\n",
        "        e = np.random.randint(0, len(da_imgs_mtx))\n",
        "        redraw = bool(e in dict_sel_idx)\n",
        "    dict_sel_idx.append(e)\n",
        "dict_sel = da.take(da_imgs_mtx, dict_sel_idx)\n",
        "\n",
        "learner = MiniBatchDictionaryLearning(\n",
        "    n_components=n_components, alpha=lambda1, n_iter=iters, fit_algorithm=\"lars\",\n",
        "    n_jobs=1, batch_size=batchsize, shuffle=True,\n",
        "    dict_init=dict_sel, transform_algorithm=\"omp\",\n",
        "    transform_n_nonzero_coefs=None, transform_alpha=None,\n",
        "    verbose=False, split_sign=False, random_state=None\n",
        ")\n",
        "dictionary = dask_store._create_dataset(\n",
        "    subgroup_dict, shape=(n_components,) + da_imgs.shape[1:], dtype=da_imgs.dtype, chunks=True\n",
        ")\n",
        "\n",
        "learner.fit(da_imgs_mtx, get=client.get)\n",
        "dictionary[:] = learner.components_.reshape((n_components,) + da_imgs.shape[1:])\n",
        "\n",
        "del dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "algorithm = \"lasso_lars\"\n",
        "alpha = 0.001\n",
        "n_nonzero_coefs = None\n",
        "max_iter = 1000\n",
        "\n",
        "\n",
        "import sklearn\n",
        "import sklearn.decomposition\n",
        "\n",
        "for k in [\"code\"]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "imgs = dask_store[subgroup_norm]\n",
        "dictionary = dask_store[subgroup_dict]\n",
        "\n",
        "imgs = imgs.astype(np.float64)\n",
        "dictionary = dictionary.astype(np.float64)\n",
        "\n",
        "dictionary = dictionary.rechunk(dictionary.ndim * (-1,))\n",
        "\n",
        "imgs = imgs.reshape((imgs.shape[0], np.prod(imgs.shape[1:])))\n",
        "dictionary = dictionary.reshape((dictionary.shape[0], np.prod(dictionary.shape[1:])))\n",
        "\n",
        "gram = da.dot(dictionary, dictionary.T)\n",
        "cov = da.dot(dictionary, imgs.T)\n",
        "\n",
        "\n",
        "def sparse_encode_wrapper(*args, **kwargs):\n",
        "    args = tuple(e[0] if isinstance(e, list) else e for e in args)\n",
        "    return sklearn.decomposition.sparse_encode(*args, **kwargs).T\n",
        "\n",
        "\n",
        "code = da.atop(\n",
        "    sparse_encode_wrapper,\n",
        "    (0, 1),\n",
        "    imgs,\n",
        "    (1, 2),\n",
        "    dictionary,\n",
        "    (0, 2),\n",
        "    gram,\n",
        "    (0, 0),\n",
        "    cov,\n",
        "    (0, 1),\n",
        "    dtype=np.float64,\n",
        "    algorithm=algorithm,\n",
        "    n_nonzero_coefs=n_nonzero_coefs,\n",
        "    alpha=alpha,\n",
        "    copy_cov=True,\n",
        "    init=None,\n",
        "    max_iter=max_iter,\n",
        "    n_jobs=1,\n",
        "    check_input=True,\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "dask_store[\"code\"] = code\n",
        "\n",
        "dask.distributed.progress(dask_store[\"code\"], notebook=False)\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets\n",
        "\n",
        "@ipywidgets.interact(i=ipywidgets.IntSlider(min=0,max=len(dictionary)-1,step=1,value=0))\n",
        "def show_basis_code_plts(i):\n",
        "    fig = plt.figure()\n",
        "    fig.add_subplot(1,2,1)\n",
        "    plt.imshow(dask_store[subgroup_dict][i])\n",
        "    fig.add_subplot(1,2,2)\n",
        "    plt.plot(dask_store[\"code\"][i])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "da_imgs = dask_store[subgroup_norm]\n",
        "da_imgs_recons = da.tensordot(dask_store[\"code\"], dask_store[subgroup_dict], axes=(0, 0))\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    (da_imgs - da_imgs_recons).max(axis=0),\n",
        "    vmin=0,\n",
        "    vmax=0.2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import functools\n",
        "import io\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "try:\n",
        "    from contextlib import ExitStack, redirect_stdout, redirect_stderr\n",
        "except ImportError:\n",
        "    from contextlib2 import ExitStack, redirect_stdout, redirect_stderr\n",
        "\n",
        "\n",
        "def func_log_stdoe(func):\n",
        "    @functools.wraps(func)\n",
        "    def wrapped(*args, **kwargs):\n",
        "        with ExitStack() as stack:\n",
        "            out, err = io.StringIO(), io.StringIO()\n",
        "\n",
        "            stack.enter_context(redirect_stdout(out))\n",
        "            stack.enter_context(redirect_stdout(err))\n",
        "\n",
        "            try:\n",
        "                return func(*args, **kwargs)\n",
        "            finally:\n",
        "                logging.getLogger(\"distributed.worker.stdout\").info(out.getvalue())\n",
        "                logging.getLogger(\"distributed.worker.stderr\").info(err.getvalue())\n",
        "\n",
        "    return wrapped\n",
        "\n",
        "\n",
        "@func_logging\n",
        "def print_hello():\n",
        "    print(\"Hello my Friends!\")\n",
        "\n",
        "client.run(print_hello)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Postprocessing\n",
        "\n",
        "* `significance_threshold` (`float`): number of standard deviations below which to include in \"noise\" estimate\n",
        "* `wavelet_scale` (`int`): scale of wavelet transform to apply (should be the same as the one used above)\n",
        "* `noise_threshold` (`float`): number of units of \"noise\" above which something needs to be to be significant\n",
        "* `accepted_region_shape_constraints` (`dict`): if ROIs don't match this, reduce the `wavelet_scale` once.\n",
        "* `percentage_pixels_below_max` (`float`): upper bound on ratio of ROI pixels not at max intensity vs. all ROI pixels\n",
        "* `min_local_max_distance` (`float`): minimum allowable euclidean distance between two ROIs maximum intensities\n",
        "* `accepted_neuron_shape_constraints` (`dict`): shape constraints for ROI to be kept.\n",
        "\n",
        "* `alignment_min_threshold` (`float`): similarity measure of the intensity of two ROIs images used for merging.\n",
        "* `overlap_min_threshold` (`float`): similarity measure of the masks of two ROIs used for merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "significance_threshold = 3.0\n",
        "wavelet_scale = 3\n",
        "noise_threshold = 3.0\n",
        "percentage_pixels_below_max = 0.8\n",
        "min_local_max_distance = 16.0\n",
        "\n",
        "alignment_min_threshold = 0.6\n",
        "overlap_min_threshold = 0.6\n",
        "\n",
        "\n",
        "for k in zarr_store.get(subgroup_post, {}).keys():\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[subgroup_post + \"/\" + k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_post]\n",
        "zarr_store.require_group(subgroup_post)\n",
        "\n",
        "\n",
        "imgs = dask_store._diskstore[subgroup_dict]\n",
        "da_imgs = da.from_array(imgs, chunks=((1,) + imgs.shape[1:]))\n",
        "\n",
        "result = block_postprocess_data_parallel(client)(da_imgs,\n",
        "                              **{\n",
        "                                    \"wavelet_denoising\" : {\n",
        "                                        \"estimate_noise\" : {\n",
        "                                            \"significance_threshold\" : significance_threshold\n",
        "                                        },\n",
        "                                        \"wavelet.transform\" : {\n",
        "                                            \"scale\" : wavelet_scale\n",
        "                                        },\n",
        "                                        \"significant_mask\" : {\n",
        "                                            \"noise_threshold\" : noise_threshold\n",
        "                                        },\n",
        "                                        \"accepted_region_shape_constraints\" : {\n",
        "                                            \"major_axis_length\" : {\n",
        "                                                \"min\" : 0.0,\n",
        "                                                \"max\" : 25.0\n",
        "                                            }\n",
        "                                        },\n",
        "                                        \"remove_low_intensity_local_maxima\" : {\n",
        "                                            \"percentage_pixels_below_max\" : percentage_pixels_below_max\n",
        "                                        },\n",
        "                                        \"remove_too_close_local_maxima\" : {\n",
        "                                            \"min_local_max_distance\" : min_local_max_distance\n",
        "                                        },\n",
        "                                        \"accepted_neuron_shape_constraints\" : {\n",
        "                                            \"area\" : {\n",
        "                                                \"min\" : 25,\n",
        "                                                \"max\" : 600\n",
        "                                            },\n",
        "                                            \"eccentricity\" : {\n",
        "                                                \"min\" : 0.0,\n",
        "                                                \"max\" : 0.9\n",
        "                                            }\n",
        "                                        }\n",
        "                                    },\n",
        "                                    \"merge_neuron_sets\" : {\n",
        "                                        \"alignment_min_threshold\" : alignment_min_threshold,\n",
        "                                        \"overlap_min_threshold\" : overlap_min_threshold,\n",
        "                                        \"fuse_neurons\" : {\n",
        "                                            \"fraction_mean_neuron_max_threshold\" : 0.01\n",
        "                                        }\n",
        "                                    }\n",
        "                              }\n",
        ")\n",
        "\n",
        "# Store projections\n",
        "dask_store.update(dict(zip(\n",
        "    [\"%s/%s\" % (subgroup_post, e) for e in result.dtype.names],\n",
        "    [result[e] for e in result.dtype.names]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[\"%s/%s\" % (subgroup_post, e)]\n",
        "        for e in result.dtype.names\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROI and trace extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dask_io_remove(data_basename + postfix_rois + h5_ext, client)\n",
        "for k in [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j, subgroup_rois]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_rois]\n",
        "zarr_store.require_group(subgroup_rois)\n",
        "\n",
        "\n",
        "da_roi_masks = dask_store[subgroup_post_mask]\n",
        "\n",
        "da_lbls = da.arange(\n",
        "    1,\n",
        "    len(da_roi_masks) + 1,\n",
        "    chunks=da_roi_masks.chunks[0],\n",
        "    dtype=np.uint64\n",
        ")\n",
        "da_lblimg = (\n",
        "    da_lbls[(slice(None),) + (da_roi_masks.ndim - 1) * (None,)] * \n",
        "    da_roi_masks.astype(np.uint64)\n",
        ").max(axis=0)\n",
        "\n",
        "dask_store.update(dict(zip(\n",
        "    [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j],\n",
        "    [da_roi_masks, da_roi_masks.astype(numpy.uint8), da_lblimg, da_lblimg.astype(numpy.uint8)]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[e] for e in\n",
        "    [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "with h5py.File(data_basename + postfix_rois + h5_ext, \"w\") as f2:\n",
        "    for k in [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j]:\n",
        "        zarr.copy(dask_store._diskstore[k], f2)\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_traces + h5_ext, client)\n",
        "for k in [subgroup_traces]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_images = dask_store[subgroup_sub]\n",
        "da_masks = dask_store[subgroup_rois_masks]\n",
        "\n",
        "da_result = compute_traces(da_images, da_masks)\n",
        "\n",
        "# Store traces\n",
        "dask_store[subgroup_traces] = da_result\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_traces], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "with h5py.File(data_basename + postfix_traces + h5_ext, \"w\") as f2:\n",
        "    zarr.copy(dask_store._diskstore[subgroup_traces], f2)\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_sub]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")\n",
        "\n",
        "lblimg = dask_store[subgroup_rois_labels].compute()\n",
        "lblimg_msk = numpy.ma.masked_array(lblimg, mask=(lblimg==0))\n",
        "\n",
        "mplsv.viewer.matshow(lblimg_msk, alpha=0.3, cmap=mpl.cm.jet)\n",
        "\n",
        "\n",
        "mskimg = None\n",
        "mskimg_j = None\n",
        "lblimg = None\n",
        "traces = None\n",
        "traces_j = None\n",
        "\n",
        "del mskimg\n",
        "del mskimg_j\n",
        "del lblimg\n",
        "del traces\n",
        "del traces_j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End of workflow. Shutdown cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import distributed\n",
        "from nanshe_workflow.par import shutdown_distributed\n",
        "\n",
        "try:\n",
        "    del dask_store\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "client = distributed.client.default_client()\n",
        "\n",
        "shutdown_distributed(client)\n",
        "\n",
        "client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare interactive projection graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "import textwrap\n",
        "import zlib\n",
        "\n",
        "import numpy\n",
        "import numpy as np\n",
        "\n",
        "import bokeh.plotting\n",
        "import bokeh.plotting as bp\n",
        "\n",
        "import bokeh.io\n",
        "import bokeh.io as bio\n",
        "\n",
        "import bokeh.embed\n",
        "import bokeh.embed as be\n",
        "\n",
        "from bokeh.models.mappers import LinearColorMapper\n",
        "\n",
        "import webcolors\n",
        "\n",
        "from bokeh.models import CustomJS, ColumnDataSource, HoverTool\n",
        "from bokeh.models.layouts import Row\n",
        "\n",
        "from builtins import (\n",
        "    map as imap,\n",
        "    range as irange\n",
        ")\n",
        "\n",
        "from past.builtins import basestring\n",
        "\n",
        "import nanshe_workflow\n",
        "from nanshe_workflow.data import io_remove, open_zarr\n",
        "from nanshe_workflow.vis import get_rgb_array, get_rgba_array, get_all_greys, masks_to_contours_2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mskimg = zarr_store[subgroup_rois_masks][...]\n",
        "\n",
        "traces = zarr_store[subgroup_traces][...]\n",
        "\n",
        "imgproj_mean = zarr_store[subgroup_proj_max][...]\n",
        "imgproj_max = zarr_store[subgroup_proj_mean][...]\n",
        "imgproj_std = zarr_store[subgroup_proj_std][...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result visualization\n",
        "\n",
        "* `proj_img` (`str` or `list` of `str`): which projection or projections to plot (e.g. \"max\", \"mean\", \"std\").\n",
        "* `block_size` (`int`): size of each point on any dimension in the image in terms of pixels.\n",
        "* `roi_alpha` (`float`): transparency of the ROIs in a range of [0.0, 1.0].\n",
        "* `roi_border_width` (`int`): width of the line border on each ROI.\n",
        "\n",
        "<br>\n",
        "* `trace_plot_width` (`int`): width of the trace plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "proj_img = \"std\"\n",
        "block_size = 1\n",
        "roi_alpha = 0.3\n",
        "roi_border_width = 3\n",
        "trace_plot_width = 500\n",
        "\n",
        "\n",
        "bio.curdoc().clear()\n",
        "\n",
        "grey_range = get_all_greys()\n",
        "grey_cm = LinearColorMapper(grey_range)\n",
        "\n",
        "colors_rgb = get_rgb_array(len(mskimg))\n",
        "colors_rgb = colors_rgb.tolist()\n",
        "colors_rgb = list(imap(webcolors.rgb_to_hex, colors_rgb))\n",
        "\n",
        "mskctr_pts_y, mskctr_pts_x = masks_to_contours_2d(mskimg)\n",
        "\n",
        "mskctr_pts_dtype = np.min_scalar_type(max(mskimg.shape[1:]) - 1)\n",
        "mskctr_pts_y = [np.array(_, dtype=mskctr_pts_dtype) for _ in mskctr_pts_y]\n",
        "mskctr_pts_x = [np.array(_, dtype=mskctr_pts_dtype) for _ in mskctr_pts_x]\n",
        "\n",
        "mskctr_srcs = ColumnDataSource(data=dict(x=mskctr_pts_x, y=mskctr_pts_y, color=colors_rgb))\n",
        "\n",
        "\n",
        "if isinstance(proj_img, basestring):\n",
        "    proj_img = [proj_img]\n",
        "else:\n",
        "    proj_img = list(proj_img)\n",
        "\n",
        "\n",
        "proj_plot_width = block_size*mskimg.shape[2]\n",
        "proj_plot_height = block_size*mskimg.shape[1]\n",
        "plot_projs = []\n",
        "\n",
        "if \"max\" in proj_img:\n",
        "    plot_max = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Max Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_max.image(image=[numpy.flipud(imgproj_max)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[imgproj_max.shape[1]], dh=[imgproj_max.shape[0]], color_mapper=grey_cm)\n",
        "    plot_max.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_max.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_max.axis)):\n",
        "        plot_max.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_max)\n",
        "\n",
        "\n",
        "if \"mean\" in proj_img:\n",
        "    plot_mean = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Mean Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_mean.image(image=[numpy.flipud(imgproj_mean)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[mskimg.shape[2]], dh=[mskimg.shape[1]], color_mapper=grey_cm)\n",
        "    plot_mean.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_mean.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_mean.axis)):\n",
        "        plot_mean.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_mean)\n",
        "\n",
        "\n",
        "if \"std\" in proj_img:\n",
        "    plot_std = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Std Dev Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_std.image(image=[numpy.flipud(imgproj_std)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[mskimg.shape[2]], dh=[mskimg.shape[1]], color_mapper=grey_cm)\n",
        "    plot_std.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_std.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_std.axis)):\n",
        "        plot_std.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_std)\n",
        "\n",
        "\n",
        "all_tr_dtype_srcs = ColumnDataSource(data=dict(traces_dtype=traces.dtype.type(0)[None]))\n",
        "all_tr_shape_srcs = ColumnDataSource(data=dict(traces_shape=traces.shape))\n",
        "all_tr_srcs = ColumnDataSource(data=dict(\n",
        "    traces=numpy.frombuffer(\n",
        "        zlib.compress(traces.tobytes()),\n",
        "        dtype=np.uint8\n",
        "    )\n",
        "))\n",
        "tr_srcs = ColumnDataSource(data=dict(times_sel=[], traces_sel=[], colors_sel=[]))\n",
        "plot_tr = bp.Figure(plot_width=trace_plot_width, plot_height=proj_plot_height,\n",
        "                    x_range=(0.0, float(traces.shape[1])), y_range=(float(traces.min()), float(traces.max())),\n",
        "                    tools=[\"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"], title=\"ROI traces\",\n",
        "                    background_fill_color=\"black\", border_fill_color=\"black\")\n",
        "plot_tr.multi_line(\"times_sel\", \"traces_sel\", source=tr_srcs, color=\"colors_sel\")\n",
        "\n",
        "plot_tr.outline_line_color = \"white\"\n",
        "for i in irange(len(plot_tr.axis)):\n",
        "    plot_tr.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "plot_projs.append(plot_tr)\n",
        "\n",
        "\n",
        "mskctr_srcs.callback = CustomJS(\n",
        "    args=dict(\n",
        "        all_tr_dtype_srcs=all_tr_dtype_srcs,\n",
        "        all_tr_shape_srcs=all_tr_shape_srcs,\n",
        "        all_tr_srcs=all_tr_srcs,\n",
        "        tr_srcs=tr_srcs\n",
        "    ), code=\"\"\"\n",
        "    var range = function(n){ return Array.from(Array(n).keys()); };\n",
        "\n",
        "    var traces_not_decoded = (all_tr_dtype_srcs.data['traces_dtype'] == 0);\n",
        "    var traces_dtype = all_tr_dtype_srcs.data['traces_dtype'].constructor;\n",
        "    var traces_shape = all_tr_shape_srcs.data['traces_shape'];\n",
        "    var trace_len = traces_shape[1];\n",
        "    var traces = all_tr_srcs.data['traces'];\n",
        "    if (traces_not_decoded) {\n",
        "        traces = window.pako.inflate(traces);\n",
        "        traces = new traces_dtype(traces.buffer);\n",
        "        all_tr_srcs.data['traces'] = traces;\n",
        "        all_tr_dtype_srcs.data['traces_dtype'] = 1;\n",
        "    }\n",
        "\n",
        "    var inds = cb_obj.selected['1d'].indices;\n",
        "    var colors = cb_obj.data['color'];\n",
        "    var selected = tr_srcs.data;\n",
        "\n",
        "    var times = range(trace_len);\n",
        "\n",
        "    selected['times_sel'] = [];\n",
        "    selected['traces_sel'] = [];\n",
        "    selected['colors_sel'] = [];\n",
        "\n",
        "    for (i = 0; i < inds.length; i++) {\n",
        "        var inds_i = inds[i];\n",
        "        var trace_i = traces.slice(trace_len*inds_i, trace_len*(inds_i+1));\n",
        "        var color_i = colors[inds_i];\n",
        "\n",
        "        selected['times_sel'].push(times);\n",
        "        selected['traces_sel'].push(trace_i);\n",
        "        selected['colors_sel'].push(color_i);\n",
        "    }\n",
        "\n",
        "    tr_srcs.change.emit();\n",
        "\"\"\")\n",
        "\n",
        "\n",
        "plot_group = Row(*plot_projs)\n",
        "\n",
        "\n",
        "# Clear out the old HTML file before writing a new one.\n",
        "io_remove(data_basename + postfix_html + html_ext)\n",
        "\n",
        "\n",
        "def indent(text, spaces):\n",
        "    spaces = \" \" * int(spaces)\n",
        "    return \"\\n\".join(imap(lambda l: spaces + l, text.splitlines()))\n",
        "\n",
        "def write_html(filename, title, div, script, cdn):\n",
        "    html_tmplt = textwrap.dedent(u\"\"\"\\\n",
        "        <html lang=\"en\">\n",
        "            <head>\n",
        "                <meta charset=\"utf-8\">\n",
        "                <title>{title}</title>\n",
        "                {cdn}\n",
        "                <style>\n",
        "                  html {{\n",
        "                    width: 100%;\n",
        "                    height: 100%;\n",
        "                  }}\n",
        "                  body {{\n",
        "                    width: 90%;\n",
        "                    height: 100%;\n",
        "                    margin: auto;\n",
        "                    background-color: black;\n",
        "                  }}\n",
        "                </style>\n",
        "            </head>\n",
        "            <body>\n",
        "                {div}\n",
        "                {script}\n",
        "            </body>\n",
        "        </html>\n",
        "    \"\"\")\n",
        "\n",
        "    html_cont = html_tmplt.format(\n",
        "        title=title,\n",
        "        div=indent(div, 8),\n",
        "        script=indent(script, 8),\n",
        "        cdn=indent(cdn, 8),\n",
        "    )\n",
        "\n",
        "    with io.open(filename, \"w\") as fh:\n",
        "        fh.write(html_cont)\n",
        "\n",
        "script, div = be.components(plot_group)\n",
        "cdn = bokeh.resources.CDN.render() + \"\\n\"\n",
        "cdn += \"\"\"\n",
        "<script type=\"text/javascript\" src=\"https://cdn.jsdelivr.net/pako/1.0.4/pako_inflate.min.js\"></script>\n",
        "\"\"\"\n",
        "cdn += \"\\n\"\n",
        "\n",
        "write_html(data_basename + postfix_html + html_ext, data_basename + postfix_html, div, script, cdn)\n",
        "\n",
        "\n",
        "from IPython.display import display, IFrame\n",
        "display(IFrame(data_basename + postfix_html + html_ext, \"100%\", 1.05*proj_plot_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test teardown. Ignore warnings during production runs.\n",
        "\n",
        "%run ./teardown_tests.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "widgets": {
      "state": {},
      "version": "1.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
