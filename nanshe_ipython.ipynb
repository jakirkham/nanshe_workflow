{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test setup. Ignore warnings during production runs.\n",
        "\n",
        "%run ./setup_tests.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Specify input data\n",
        "\n",
        "* `data_dir` (`str`): Where the data is located. (change if data is not in the current directory, normally is)\n",
        "* `data` (`str`): HDF5 file to use as input data.\n",
        "* `data_basename` (`str`): Basename to use for intermediate and final result files.\n",
        "* `dataset` (`str`): HDF5 dataset to use as input data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_dir = \"\"\n",
        "data = \"034_p2_g7_dsbars_200um_rigid_reg.tif\"\n",
        "data_basename = \"034_p2_g7_dsbars_200um_rigid_reg\"\n",
        "dataset = \"images\"\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "data_ext = os.path.splitext(data)[1].lower()\n",
        "data_dir = os.path.abspath(data_dir)\n",
        "\n",
        "subgroup_raw = \"raw\"\n",
        "subgroup_trim = \"trim\"\n",
        "subgroup_dn = \"dn\"\n",
        "subgroup_reg = \"reg\"\n",
        "subgroup_reg_images = \"reg/images\"\n",
        "subgroup_reg_shifts = \"reg/shifts\"\n",
        "subgroup_sub = \"sub\"\n",
        "subgroup_norm = \"norm\"\n",
        "subgroup_dict_init_data = \"dict_init_data\"\n",
        "subgroup_dict_init_dict = \"dict_init_dict\"\n",
        "subgroup_dict = \"dict\"\n",
        "subgroup_code = \"code\"\n",
        "subgroup_post = \"post\"\n",
        "subgroup_post_mask = \"post/mask\"\n",
        "subgroup_rois = \"rois\"\n",
        "subgroup_rois_masks = \"rois/masks\"\n",
        "subgroup_rois_masks_j = \"rois/masks_j\"\n",
        "subgroup_rois_labels = \"rois/labels\"\n",
        "subgroup_rois_labels_j = \"rois/labels_j\"\n",
        "subgroup_traces = \"traces\"\n",
        "subgroup_proj = \"proj\"\n",
        "subgroup_proj_hmean = \"proj/hmean\"\n",
        "subgroup_proj_max = \"proj/max\"\n",
        "subgroup_proj_mean = \"proj/mean\"\n",
        "subgroup_proj_std = \"proj/std\"\n",
        "\n",
        "postfix_rois = \"_rois\"\n",
        "postfix_traces = \"_traces\"\n",
        "postfix_html = \"_proj\"\n",
        "\n",
        "h5_ext = os.path.extsep + \"h5\"\n",
        "tiff_ext = os.path.extsep + \"tif\"\n",
        "zarr_ext = os.path.extsep + \"zarr\"\n",
        "html_ext = os.path.extsep + \"html\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from psutil import cpu_count\n",
        "\n",
        "cluster_kwargs = {\n",
        "    \"ip\": \"\"\n",
        "}\n",
        "client_kwargs = {}\n",
        "adaptive_kwargs = {\n",
        "    \"minimum\": 0,\n",
        "    \"maximum\": int(os.environ.get(\"CORES\", cpu_count())) - 1\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import zarr\n",
        "\n",
        "from nanshe_workflow.data import DistributedDirectoryStore\n",
        "\n",
        "zarr_store = zarr.open_group(DistributedDirectoryStore(data_basename + zarr_ext), \"a\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Configure and startup Cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.par import startup_distributed\n",
        "from nanshe_workflow.data import DistributedArrayStore\n",
        "\n",
        "client = startup_distributed(0, cluster_kwargs, client_kwargs, adaptive_kwargs)\n",
        "\n",
        "dask_store = DistributedArrayStore(zarr_store, client=client)\n",
        "\n",
        "client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "client.cluster"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Define functions for computation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%matplotlib notebook\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.cm\n",
        "import matplotlib.pyplot\n",
        "\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from mplview.core import MatplotlibViewer as MPLViewer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ctypes\n",
        "import logging\n",
        "import os\n",
        "import importlib\n",
        "import sys\n",
        "\n",
        "from builtins import (\n",
        "    map as imap,\n",
        "    range as irange\n",
        ")\n",
        "from past.builtins import basestring\n",
        "\n",
        "try:\n",
        "    from contextlib import suppress\n",
        "except ImportError:\n",
        "    from contextlib2 import suppress\n",
        "\n",
        "import numpy\n",
        "import h5py\n",
        "\n",
        "import numpy as np\n",
        "import h5py as hp\n",
        "\n",
        "import dask\n",
        "import dask.array\n",
        "import dask.array.fft\n",
        "import dask.distributed\n",
        "try:\n",
        "    from dask.highlevelgraph import HighLevelGraph\n",
        "except ImportError:\n",
        "    import dask.sharedict as HighLevelGraph\n",
        "\n",
        "import dask.array as da\n",
        "\n",
        "import dask_image\n",
        "import dask_image.imread\n",
        "import dask_image.ndfilters\n",
        "import dask_image.ndfourier\n",
        "\n",
        "import zarr\n",
        "\n",
        "import nanshe\n",
        "from nanshe.imp.segment import generate_dictionary\n",
        "\n",
        "import nanshe_workflow\n",
        "import nanshe_workflow._reg_joblib\n",
        "from nanshe_workflow.data import io_remove, dask_io_remove, dask_load_hdf5, dask_store_zarr, zip_zarr, open_zarr\n",
        "\n",
        "zarr.blosc.set_nthreads(1)\n",
        "zarr.blosc.use_threads = False\n",
        "client.run(zarr.blosc.set_nthreads, 1)\n",
        "client.run(setattr, zarr.blosc, \"use_threads\", False)\n",
        "\n",
        "logging.getLogger(\"nanshe\").setLevel(logging.INFO)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.data import DistributedDirectoryStore\n",
        "from nanshe_workflow.data import hdf5_to_zarr, zarr_to_hdf5\n",
        "from nanshe_workflow.data import save_tiff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    import pyfftw.interfaces.dask_fft as dask_fft\n",
        "except ImportError:\n",
        "    import dask.array.fft as dask_fft"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.reg import fourier_shift_wrap, compute_offset, roll_frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.imp2 import extract_f0, wavelet_transform, renormalized_images, normalize_data\n",
        "\n",
        "from nanshe_workflow.par import halo_block_generate_dictionary_parallel\n",
        "from nanshe_workflow.imp import block_postprocess_data_parallel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.proj2 import compute_traces\n",
        "\n",
        "from nanshe_workflow.proj2 import compute_adj_harmonic_mean_projection\n",
        "\n",
        "from nanshe_workflow.proj2 import norm_layer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Begin workflow. Set parameters and run each cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Convert TIFF/HDF5 to Zarr\n",
        "\n",
        "* `block_chunks` (`tuple` of `int`s): chunk size for each block loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "block_chunks = (50, -1, -1)\n",
        "\n",
        "for k in [subgroup_raw]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "dask_ingest_func = None\n",
        "if data_ext == tiff_ext:\n",
        "    dask_ingest_func = lambda data: dask_image.imread.imread(data, nframes=block_chunks[0])\n",
        "elif data_ext == h5_ext:\n",
        "    dask_ingest_func = lambda data: dask_load_hdf5(data, dataset=dataset, chunks=block_chunks)\n",
        "\n",
        "\n",
        "if isinstance(data, basestring):\n",
        "    dask_store[subgroup_raw] = dask_ingest_func(data)\n",
        "else:\n",
        "    dask_store[subgroup_raw] = da.concatenate(list(imap(dask_ingest_func, data)))\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_raw], notebook=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### View Input Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_raw]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Trimming\n",
        "\n",
        "* `front` (`int`): amount to trim off the front\n",
        "* `back` (`int`): amount to trim off the back"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "front = 1\n",
        "back = 0\n",
        "top = 0\n",
        "bottom = 0\n",
        "left = 3\n",
        "right = 0\n",
        "\n",
        "\n",
        "for k in [subgroup_trim]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_raw]\n",
        "\n",
        "# Trim frames from front and back\n",
        "da_imgs_trim = da_imgs[1:, :, 3:]\n",
        "# da_imgs_trim = da_imgs[front:da_imgs.shape[0]-back, top:da_imgs.shape[1]-bottom, left:da_imgs.shape[2]-right]\n",
        "\n",
        "# Store trimmed data\n",
        "dask_store[subgroup_trim] = da_imgs_trim\n",
        "\n",
        "# Check progress of store step\n",
        "dask.distributed.progress(dask_store[subgroup_trim], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_trim]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Denoising\n",
        "\n",
        "* `med_filt_size` (`int`): footprint size for median filter\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "med_filt_size = 1\n",
        "\n",
        "\n",
        "for k in [subgroup_dn]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_trim]\n",
        "\n",
        "# Median filter frames\n",
        "da_imgs_filt = dask_image.ndfilters.median_filter(\n",
        "    da_imgs, (1,) + (da_imgs.ndim - 1) * (med_filt_size,)\n",
        ")\n",
        "\n",
        "# Reset minimum to original value.\n",
        "da_imgs_min = da_imgs.min()\n",
        "da_imgs_filt_min = da_imgs_filt.min()\n",
        "da_imgs_filt += da_imgs_min - da_imgs_filt_min\n",
        "\n",
        "# Store denoised data\n",
        "da_imgs_min, da_imgs_filt, da_imgs_filt_min = dask.persist(da_imgs_min, da_imgs_filt, da_imgs_filt_min)\n",
        "dask_store[subgroup_dn] = da_imgs_filt\n",
        "del da_imgs_min, da_imgs_filt, da_imgs_filt_min\n",
        "\n",
        "# Check progress of store step\n",
        "dask.distributed.progress(dask_store[subgroup_dn], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_dn]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Registration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_reps = 1\n",
        "tmpl_hist_wght = 1.00\n",
        "thld_rel_dist = 0.0\n",
        "\n",
        "\n",
        "for k in [subgroup_reg_images, subgroup_reg_shifts]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_reg]\n",
        "zarr_store.require_group(subgroup_reg)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_dn]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "# Create frame shape arrays\n",
        "frame_shape = np.array(da_imgs_flt.shape[1:], dtype=int)\n",
        "half_frame_shape = frame_shape // 2\n",
        "frame_shape = da.asarray(frame_shape)\n",
        "half_frame_shape = da.asarray(half_frame_shape)\n",
        "\n",
        "# Find the inverse of each frame\n",
        "da_imgs_flt_min = da_imgs_flt.min()\n",
        "da_imgs_inv = dask.array.reciprocal(da_imgs_flt - (da_imgs_flt_min - 1))\n",
        "\n",
        "# Compute the FFT of inverse frames and template\n",
        "da_imgs_fft = dask_fft.rfftn(da_imgs_inv, axes=tuple(irange(1, da_imgs_flt.ndim)))\n",
        "da_imgs_fft_tmplt = da_imgs_fft.mean(axis=0, keepdims=True)\n",
        "\n",
        "# Initialize\n",
        "i = 0\n",
        "avg_rel_dist = 1.0\n",
        "tmpl_hist_wght = da_imgs_flt.dtype.type(tmpl_hist_wght)\n",
        "da_shifts = da.zeros(\n",
        "    (len(da_imgs_fft), da_imgs_fft.ndim - 1),\n",
        "    dtype=int,\n",
        "    chunks=(da_imgs_fft.chunks[0], (da_imgs_fft.ndim - 1,))\n",
        ")\n",
        "\n",
        "# Persist FFT of frames and template\n",
        "da_imgs_flt_min, da_imgs_fft, da_imgs_fft_tmplt = client.persist([\n",
        "    da_imgs_flt_min, da_imgs_fft, da_imgs_fft_tmplt\n",
        "])\n",
        "del da_imgs_flt_min\n",
        "\n",
        "while avg_rel_dist > thld_rel_dist and i < num_reps:\n",
        "    # Compute the shifted frames\n",
        "    da_shifted_frames = da.atop(\n",
        "        fourier_shift_wrap,\n",
        "        (0,) + tuple(irange(1, da_imgs_fft.ndim)),\n",
        "        da_imgs_fft,\n",
        "        (0,) + tuple(irange(1, da_imgs_fft.ndim)),\n",
        "        da_shifts,\n",
        "        (0, da_imgs_fft.ndim),\n",
        "        dtype=da_imgs_fft.dtype\n",
        "    )\n",
        "\n",
        "    # Compute the template FFT\n",
        "    da_imgs_fft_tmplt = (\n",
        "        tmpl_hist_wght * da_imgs_fft_tmplt +\n",
        "        (1 - tmpl_hist_wght) * da_shifted_frames.mean(axis=0, keepdims=True)\n",
        "    )\n",
        "\n",
        "    # Persist the updated FFT template\n",
        "    da_shifted_frames, da_imgs_fft_tmplt = client.persist([\n",
        "        da_shifted_frames, da_imgs_fft_tmplt\n",
        "    ])\n",
        "    del da_shifted_frames\n",
        "\n",
        "    # Find the best overlap with the template.\n",
        "    da_overlap = dask_fft.irfftn(\n",
        "        da_imgs_fft * da_imgs_fft_tmplt,\n",
        "        s=da_imgs_flt.shape[1:],\n",
        "        axes=tuple(irange(1, da_imgs_flt.ndim))\n",
        "    )\n",
        "    da_overlap_max = da_overlap.max(axis=tuple(irange(1, da_imgs_flt.ndim)), keepdims=True)\n",
        "    da_overlap_max_match = (da_overlap == da_overlap_max)\n",
        "\n",
        "    # Clear FFT overlap intermediates\n",
        "    del da_overlap_max\n",
        "\n",
        "    # Compute the shift for each frame.\n",
        "    old_da_shifts = da_shifts\n",
        "    da_raw_shifts = da.atop(\n",
        "        compute_offset,\n",
        "        (0, da_overlap_max_match.ndim),\n",
        "        da_overlap_max_match.rechunk(dict(enumerate(da_overlap_max_match.shape[1:], 1))),\n",
        "        tuple(irange(0, da_overlap_max_match.ndim)),\n",
        "        dtype=int,\n",
        "        new_axes={da_overlap_max_match.ndim: da_overlap_max_match.ndim - 1}\n",
        "    )\n",
        "\n",
        "    # Free connected persisted values\n",
        "    del da_overlap_max_match\n",
        "\n",
        "    # Remove any collective frame drift.\n",
        "    da_drift = da_raw_shifts.mean(axis=0, keepdims=True).round().astype(da_shifts.dtype)\n",
        "    da_shifts = da_raw_shifts - da_drift\n",
        "\n",
        "    # Clear drift corrected shifts\n",
        "    del da_drift\n",
        "\n",
        "    # Find shift change.\n",
        "    diff_da_shifts = da_shifts - old_da_shifts\n",
        "    rel_diff_da_shifts = (\n",
        "        diff_da_shifts.astype(da_imgs_flt.dtype) / \n",
        "        frame_shape.astype(da_imgs_flt.dtype) /\n",
        "        np.sqrt(da_imgs_flt.dtype.type(len(frame_shape)))\n",
        "    )\n",
        "    rel_dist_da_shifts = da.sqrt(da.square(rel_diff_da_shifts).sum(axis=1))\n",
        "    avg_rel_dist = rel_dist_da_shifts.sum() / da_imgs_flt.dtype.type(len(da_shifts))\n",
        "\n",
        "    # Free old shifts\n",
        "    del old_da_shifts\n",
        "\n",
        "    # Persist statistics related to shift change\n",
        "    da_overlap, da_raw_shifts, diff_da_shifts, rel_diff_da_shifts, rel_dist_da_shifts, avg_rel_dist = client.persist([\n",
        "        da_overlap, da_raw_shifts, diff_da_shifts, rel_diff_da_shifts, rel_dist_da_shifts, avg_rel_dist\n",
        "    ])\n",
        "    del da_overlap\n",
        "    del da_raw_shifts\n",
        "    del diff_da_shifts\n",
        "    del rel_diff_da_shifts\n",
        "    del rel_dist_da_shifts\n",
        "\n",
        "    # Compute change\n",
        "    dask.distributed.progress(avg_rel_dist, notebook=False)\n",
        "    print(\"\")\n",
        "    avg_rel_dist = avg_rel_dist.compute()\n",
        "    i += 1\n",
        "\n",
        "    # Show change\n",
        "    print((i, avg_rel_dist))\n",
        "\n",
        "# Drop unneeded items\n",
        "del frame_shape\n",
        "del half_frame_shape\n",
        "del da_imgs_flt\n",
        "del da_imgs_inv\n",
        "del da_imgs_fft\n",
        "del da_imgs_fft_tmplt\n",
        "\n",
        "# Roll all parts to clip to one side\n",
        "# Keep origin static\n",
        "da_imgs_shifted = roll_frames(\n",
        "    da_imgs,\n",
        "    da.clip(da_shifts, None, 0)\n",
        ")\n",
        "\n",
        "# Truncate all frames to smallest one\n",
        "da_imgs_trunc_shape = da.asarray(da_imgs.shape[1:]) - abs(da_shifts).max(axis=0)\n",
        "da_imgs_trunc_shape = da_imgs_trunc_shape.compute()\n",
        "\n",
        "da_imgs_trunc_cut = tuple(map(\n",
        "    lambda s: slice(None, s), da_imgs_trunc_shape\n",
        "))\n",
        "\n",
        "da_imgs_trunc = da_imgs_shifted[(slice(None),) + da_imgs_trunc_cut]\n",
        "\n",
        "# Free raw data\n",
        "del da_imgs\n",
        "\n",
        "# Store registered data\n",
        "dask_store.update({\n",
        "    subgroup_reg_images: da_imgs_trunc,\n",
        "    subgroup_reg_shifts: da_shifts,\n",
        "})\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[subgroup_reg_images],\n",
        "        dask_store[subgroup_reg_shifts]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")\n",
        "\n",
        "# Free truncated frames and shifts\n",
        "del da_imgs_trunc\n",
        "del da_shifts\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_reg_images]\n",
        "da_shifts = dask_store[subgroup_reg_shifts]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "fig, axs = plt.subplots(nrows=da_shifts.shape[1], sharex=True)\n",
        "fig.subplots_adjust(hspace=0.0)\n",
        "for i in range(da_shifts.shape[1]):\n",
        "    axs[i].plot(np.asarray(da_shifts[:, i]))\n",
        "    axs[i].set_ylabel(\"%s (px)\" % chr(ord(\"X\") + da_shifts.shape[1] - i - 1))\n",
        "    axs[i].yaxis.set_tick_params(width=1.5)\n",
        "    [v.set_linewidth(2) for v in axs[i].spines.values()]\n",
        "axs[-1].set_xlabel(\"Frame (#)\")\n",
        "axs[-1].set_xlim((0, da_shifts.shape[0] - 1))\n",
        "axs[-1].xaxis.set_tick_params(width=1.5)\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Projections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_proj_hmean, subgroup_proj_max, subgroup_proj_mean, subgroup_proj_std]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_proj]\n",
        "zarr_store.require_group(subgroup_proj)\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_dn]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_proj_hmean = compute_adj_harmonic_mean_projection(da_imgs_flt)\n",
        "\n",
        "da_imgs_proj_max = da_imgs_flt.max(axis=0)\n",
        "\n",
        "da_imgs_proj_mean, da_imgs_proj_std = da_imgs_flt.mean(axis=0), da_imgs_flt.std(axis=0)\n",
        "\n",
        "# Store projections\n",
        "dask_store.update(dict(zip(\n",
        "    [subgroup_proj_hmean, subgroup_proj_max, subgroup_proj_mean, subgroup_proj_std],\n",
        "    [da_imgs_proj_hmean, da_imgs_proj_max, da_imgs_proj_mean, da_imgs_proj_std]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[subgroup_proj_hmean],\n",
        "        dask_store[subgroup_proj_max],\n",
        "        dask_store[subgroup_proj_mean],\n",
        "        dask_store[subgroup_proj_std]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    dask_store[subgroup_proj_max],\n",
        "    vmin=0,\n",
        "    vmax=100\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Subtract Projection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_sub]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_dn]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_sub = da_imgs_flt - compute_adj_harmonic_mean_projection(da_imgs_flt)\n",
        "da_imgs_sub -= da_imgs_sub.min()\n",
        "\n",
        "# Store background removed data\n",
        "dask_store[subgroup_sub] = da_imgs_sub\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_sub], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_sub]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Normalize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_norm]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_imgs = dask_store[subgroup_dn]\n",
        "\n",
        "da_imgs_flt = da_imgs\n",
        "if not (issubclass(da_imgs_flt.dtype.type, np.floating) and \n",
        "        da_imgs_flt.dtype.itemsize >= 4):\n",
        "    da_imgs_flt = da_imgs_flt.astype(np.float32)\n",
        "\n",
        "da_imgs_flt_mins = da_imgs_flt.min(\n",
        "    axis=tuple(irange(1, da_imgs_flt.ndim)),\n",
        "    keepdims=True\n",
        ")\n",
        "\n",
        "da_imgs_flt_shift = da_imgs_flt - da_imgs_flt_mins\n",
        "\n",
        "da_result = renormalized_images(da_imgs_flt_shift)\n",
        "\n",
        "# Store normalized data\n",
        "dask_store[subgroup_norm] = da_result\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_norm], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_norm]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dictionary Learning\n",
        "\n",
        "* `n_components` (`int`): number of basis images in the dictionary.\n",
        "* `batchsize` (`int`): minibatch size to use.\n",
        "* `iters` (`int`): number of iterations to run before getting dictionary.\n",
        "* `lambda1` (`float`): weight for L<sup>1</sup> sparisty enforcement on sparse code.\n",
        "* `lambda2` (`float`): weight for L<sup>2</sup> sparisty enforcement on sparse code.\n",
        "\n",
        "<br>\n",
        "* `block_frames` (`int`): number of frames to work with in each full frame block (run in parallel)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import functools\n",
        "import itertools\n",
        "import logging\n",
        "import operator\n",
        "import sys\n",
        "\n",
        "from builtins import filter as ifilter\n",
        "\n",
        "import toolz\n",
        "import toolz.itertoolz\n",
        "\n",
        "import sklearn\n",
        "from sklearn.base import BaseEstimator\n",
        "from sklearn.decomposition.dict_learning import SparseCodingMixin\n",
        "\n",
        "try:\n",
        "    from contextlib import ExitStack, suppress, redirect_stdout, redirect_stderr\n",
        "except ImportError:\n",
        "    from contextlib2 import ExitStack, suppress, redirect_stdout, redirect_stderr\n",
        "\n",
        "try:\n",
        "    from StringIO import StringIO\n",
        "except ImportError:\n",
        "    from io import StringIO\n",
        "\n",
        "\n",
        "def to_tuple(*args):\n",
        "    return tuple(args)\n",
        "\n",
        "\n",
        "def func_log_stdoe(func):\n",
        "    @functools.wraps(func)\n",
        "    def wrapped(*args, **kwargs):\n",
        "        with ExitStack() as stack:\n",
        "            out, err = StringIO(), StringIO()\n",
        "\n",
        "            stack.enter_context(redirect_stdout(out))\n",
        "            stack.enter_context(redirect_stdout(err))\n",
        "\n",
        "            try:\n",
        "                return func(*args, **kwargs)\n",
        "            finally:\n",
        "                logging.getLogger(\"distributed.worker.stdout\").info(out.getvalue())\n",
        "                logging.getLogger(\"distributed.worker.stderr\").info(err.getvalue())\n",
        "\n",
        "    return wrapped\n",
        "\n",
        "\n",
        "def dict_learning_online(X, n_components=2, alpha=1, n_iter=100,\n",
        "                         return_code=True, dict_init=None, callback=None,\n",
        "                         batch_size=3, verbose=False, shuffle=True, n_jobs=1,\n",
        "                         method='lars', iter_offset=0, random_state=None,\n",
        "                         return_inner_stats=False, inner_stats_A=None,\n",
        "                         inner_stats_B=None, return_n_iter=False):\n",
        "    if inner_stats_A is None or inner_stats_B is None:\n",
        "        inner_stats = None\n",
        "    else:\n",
        "        inner_stats = (inner_stats_A, inner_stats_B)\n",
        "\n",
        "    with sklearn.externals.joblib.parallel_backend(\"sequential\"):\n",
        "        result = sklearn.decomposition.dict_learning_online(X, n_components=n_components, alpha=alpha,\n",
        "                                                            n_iter=n_iter, return_code=return_code,\n",
        "                                                            dict_init=np.require(dict_init, requirements=\"OW\"),\n",
        "                                                            callback=callback, batch_size=batch_size, verbose=verbose,\n",
        "                                                            shuffle=shuffle, n_jobs=n_jobs, method=method,\n",
        "                                                            iter_offset=iter_offset, random_state=random_state,\n",
        "                                                            return_inner_stats=return_inner_stats,\n",
        "                                                            inner_stats=inner_stats,\n",
        "                                                            return_n_iter=return_n_iter)\n",
        "\n",
        "    components_, inner_stats_ = result\n",
        "    inner_stats_A_, inner_stats_B_ = inner_stats_\n",
        "    return components_, inner_stats_A_, inner_stats_B_\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MiniBatchDictionaryLearning(BaseEstimator, SparseCodingMixin):\n",
        "    def __init__(self,\n",
        "                 n_components=None,\n",
        "                 alpha=1,\n",
        "                 n_iter=1000,\n",
        "                 fit_algorithm=\"lars\",\n",
        "                 batch_size=3,\n",
        "                 shuffle=True,\n",
        "                 dict_init=None,\n",
        "                 transform_algorithm=\"omp\",\n",
        "                 transform_n_nonzero_coefs=None,\n",
        "                 transform_alpha=None,\n",
        "                 verbose=False):\n",
        "        self.n_components = n_components\n",
        "        self.alpha = alpha\n",
        "        self.n_iter = n_iter\n",
        "        self.fit_algorithm = fit_algorithm\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.dict_init = dict_init\n",
        "        self.transform_algorithm = transform_algorithm\n",
        "        self.transform_n_nonzero_coefs = transform_n_nonzero_coefs\n",
        "        self.transform_alpha = transform_alpha\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.components_ = self.dict_init\n",
        "        if self.components_ is not None:\n",
        "            self.components_ = da.asarray(self.components_)\n",
        "            self.components_ = self.components_.rechunk(self.components_.shape)\n",
        "\n",
        "        self.iter_offset_ = 0\n",
        "        self.inner_stats_ = None\n",
        "\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        X = da.asarray(X)\n",
        "\n",
        "        n_components = self.n_components\n",
        "        n_features = X.shape[1]\n",
        "\n",
        "        components_ = self.components_\n",
        "        inner_stats_ = self.inner_stats_\n",
        "\n",
        "        X_get = toolz.curry(\n",
        "            operator.getitem,\n",
        "            X.rechunk((1, X.shape[1]))\n",
        "        )\n",
        "        if components_ is None:\n",
        "            idx = np.random.permutation(X.shape[0])[:n_components]\n",
        "            components_ = da.stack([X_get(i) for i in idx.flat]).rechunk({0: n_components})\n",
        "        if self.shuffle:\n",
        "            idx = np.random.permutation(X.shape[0])\n",
        "            X = da.stack([X_get(i) for i in idx.flat]).rechunk({0: X.chunks[0]})\n",
        "        if inner_stats_ is None:\n",
        "            inner_stats_ = (\n",
        "                da.zeros((n_components, n_components), chunks=(n_components, n_components)),\n",
        "                da.zeros((n_features, n_components), chunks=(n_features, n_components))\n",
        "            )\n",
        "\n",
        "        func = dict_learning_online\n",
        "        if self.verbose:\n",
        "            func = func_log_stdoe(dict_learning_online)\n",
        "\n",
        "        for X_chk_key in dask.core.flatten(X.__dask_keys__()):\n",
        "            components_key = next(dask.core.flatten(components_.__dask_keys__()))\n",
        "            if inner_stats_:\n",
        "                inner_stats_A_key = next(dask.core.flatten(inner_stats_[0].__dask_keys__()))\n",
        "                inner_stats_B_key = next(dask.core.flatten(inner_stats_[1].__dask_keys__()))\n",
        "            else:\n",
        "                inner_stats_ = tuple()\n",
        "                inner_stats_A_key = None\n",
        "                inner_stats_B_key = None\n",
        "\n",
        "            kwargs = dict(\n",
        "                n_components=n_components,\n",
        "                alpha=self.alpha,\n",
        "                n_iter=self.n_iter,\n",
        "                return_code=False,\n",
        "                dict_init=components_key,\n",
        "                callback=None,\n",
        "                batch_size=self.batch_size,\n",
        "                verbose=self.verbose,\n",
        "                shuffle=False,\n",
        "                n_jobs=1,\n",
        "                method=self.fit_algorithm,\n",
        "                iter_offset=self.iter_offset_,\n",
        "                random_state=None,\n",
        "                return_inner_stats=True,\n",
        "                inner_stats_A=inner_stats_A_key,\n",
        "                inner_stats_B=inner_stats_B_key,\n",
        "                return_n_iter=False\n",
        "            )\n",
        "\n",
        "            tok = dask.base.tokenize(X_chk_key, **kwargs)\n",
        "            components_res_key = (\"components_dict_learning_online-%s\" % tok, 0, 0)\n",
        "            inner_stat_A_res_key = (\"inner_stat_A_dict_learning_online-%s\" % tok, 0, 0)\n",
        "            inner_stat_B_res_key = (\"inner_stat_B_dict_learning_online-%s\" % tok, 0, 0)\n",
        "            dict_learn_key = \"dict_learning_online-%s\" % tok\n",
        "\n",
        "            dct = HighLevelGraph.merge(\n",
        "                {components_res_key: (\n",
        "                    operator.getitem, dict_learn_key, 0\n",
        "                )},\n",
        "                {inner_stat_A_res_key: (\n",
        "                    operator.getitem, dict_learn_key, 1\n",
        "                )},\n",
        "                {inner_stat_B_res_key: (\n",
        "                    operator.getitem, dict_learn_key, 2\n",
        "                )},\n",
        "                {dict_learn_key:\n",
        "                    (dask.compatibility.apply, func, [X_chk_key], kwargs),\n",
        "                },\n",
        "                X.__dask_graph__(),\n",
        "                components_.__dask_graph__(),\n",
        "                *(e.__dask_graph__() for e in inner_stats_)\n",
        "            )\n",
        "            dct = da.Array.__dask_optimize__(dct, [\n",
        "                components_res_key,\n",
        "                inner_stat_A_res_key,\n",
        "                inner_stat_B_res_key\n",
        "            ])\n",
        "\n",
        "            components_ = da.Array(\n",
        "                dct, components_res_key[0], ((n_components,), (n_features,)), X.dtype\n",
        "            )\n",
        "            inner_stats_ = (\n",
        "                da.Array(\n",
        "                    dct, inner_stat_A_res_key[0], ((n_components,), (n_components,)), X.dtype\n",
        "                ),\n",
        "                da.Array(\n",
        "                    dct, inner_stat_B_res_key[0], ((n_features,), (n_components,)), X.dtype\n",
        "                ),\n",
        "            )\n",
        "\n",
        "            # Persist everything after an iteration\n",
        "            result = dask.persist(components_, *inner_stats_)\n",
        "            components_, inner_stats_ = result[0], result[1:]\n",
        "\n",
        "            self.iter_offset_ += self.n_iter\n",
        "\n",
        "        self.components_ = components_\n",
        "        self.inner_stats_ = inner_stats_\n",
        "\n",
        "        return self\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def _sparse_encode_wrapper(*args, **kwargs):\n",
        "        args = tuple(e[0] if isinstance(e, list) else e for e in args)\n",
        "        return sklearn.decomposition.sparse_encode(*args, **kwargs)\n",
        "\n",
        "\n",
        "    def transform(self, X):\n",
        "        sparse_encode_wrapper = MiniBatchDictionaryLearning._sparse_encode_wrapper\n",
        "        if self.verbose:\n",
        "            sparse_encode_wrapper = func_log_stdoe(sparse_encode_wrapper)\n",
        "\n",
        "        gram = da.tensordot(self.components_, self.components_, axes=[[1], [1]])\n",
        "        cov = da.tensordot(self.components_, X, axes=[[1], [1]])\n",
        "\n",
        "        code = da.atop(\n",
        "            sparse_encode_wrapper,\n",
        "            (1, 0),\n",
        "            X,\n",
        "            (1, 2),\n",
        "            self.components_,\n",
        "            (0, 2),\n",
        "            gram,\n",
        "            (0, 0),\n",
        "            cov,\n",
        "            (0, 1),\n",
        "            dtype=self.components_.dtype,\n",
        "            algorithm=self.transform_algorithm,\n",
        "            n_nonzero_coefs=self.transform_n_nonzero_coefs,\n",
        "            alpha=self.transform_alpha,\n",
        "            copy_cov=True,\n",
        "            init=None,\n",
        "            max_iter=self.n_iter,\n",
        "            n_jobs=1,\n",
        "            check_input=False,\n",
        "            verbose=self.verbose\n",
        "        )\n",
        "        gram, cov, code = dask.persist(gram, cov, code)\n",
        "\n",
        "        return code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import toolz\n",
        "\n",
        "\n",
        "n_components = 20\n",
        "\n",
        "\n",
        "for k in [subgroup_dict_init_data, subgroup_dict_init_dict]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "da_imgs = dask_store[subgroup_norm]\n",
        "\n",
        "# Reshape to matrix and provide frame selector\n",
        "da_imgs_mtx = da_imgs.reshape(\n",
        "    da_imgs.shape[0],\n",
        "    int(np.prod(da_imgs.shape[1:]))\n",
        ")\n",
        "da_imgs_mtx_get = toolz.curry(\n",
        "    operator.getitem,\n",
        "    da_imgs_mtx.rechunk((1, da_imgs_mtx.shape[1]))\n",
        ")\n",
        "\n",
        "# Create shuffled data\n",
        "idx = np.random.permutation(da_imgs_mtx.shape[0])\n",
        "dict_init_data = da.stack([da_imgs_mtx_get(i) for i in idx.flat])\n",
        "dict_init_data = dict_init_data.rechunk({0: da_imgs_mtx.chunks[0]})\n",
        "\n",
        "# Create dictionary subsample\n",
        "idx = np.random.permutation(da_imgs_mtx.shape[0])[:n_components]\n",
        "dict_init_dict = da.stack([da_imgs_mtx_get(i) for i in idx.flat])\n",
        "dict_init_dict = dict_init_dict.rechunk({0: n_components})\n",
        "\n",
        "\n",
        "# Store shuffled data\n",
        "dask_store.update(dict(zip(\n",
        "    [subgroup_dict_init_data, subgroup_dict_init_dict],\n",
        "    [dict_init_data, dict_init_dict]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[subgroup_dict_init_data],\n",
        "        dask_store[subgroup_dict_init_dict]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from nanshe_workflow.par import startup_distributed, shutdown_distributed\n",
        "from nanshe_workflow.data import DistributedArrayStore\n",
        "from psutil import cpu_count\n",
        "\n",
        "\n",
        "ncores = int(os.environ.get(\"CORES\", cpu_count())) - 1\n",
        "\n",
        "\n",
        "dict_client = startup_distributed(\n",
        "    1,\n",
        "    cluster_kwargs={\n",
        "        \"threads_per_worker\": ncores\n",
        "    },\n",
        "    client_kwargs={}\n",
        ")\n",
        "dict_client.run(importlib.import_module, \"nanshe_workflow._reg_joblib\")\n",
        "dict_client.run(\n",
        "    lambda n: ctypes.CDLL(ctypes.util.find_library(\"openblas\")).openblas_set_num_threads(n),\n",
        "    ncores\n",
        ")\n",
        "display(dict_client)\n",
        "\n",
        "\n",
        "dict_dask_store = DistributedArrayStore(zarr_store, client=dict_client)\n",
        "\n",
        "for k in [subgroup_dict]:\n",
        "    with suppress(KeyError):\n",
        "        del dict_dask_store[k]\n",
        "\n",
        "learner = MiniBatchDictionaryLearning(\n",
        "    n_components=len(dict_dask_store[subgroup_dict_init_dict]),\n",
        "    alpha=0.4,\n",
        "    n_iter=100,\n",
        "    fit_algorithm=\"lars\",\n",
        "    batch_size=50,\n",
        "    shuffle=False,\n",
        "    dict_init=dict_dask_store[subgroup_dict_init_dict],\n",
        "    transform_algorithm=\"omp\",\n",
        "    transform_n_nonzero_coefs=None,\n",
        "    transform_alpha=0.01,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "learner.fit(dict_dask_store[subgroup_dict_init_data])\n",
        "\n",
        "dictionary = learner.components_\n",
        "dictionary = dictionary.reshape((dictionary.shape[0],) + dict_dask_store[subgroup_norm].shape[1:])\n",
        "dictionary = dictionary.persist()\n",
        "\n",
        "dict_dask_store[subgroup_dict] = dictionary\n",
        "del dictionary\n",
        "\n",
        "learner.components_ = dict_dask_store[subgroup_dict].reshape(learner.components_.shape)\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dict_dask_store[subgroup_dict],\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")\n",
        "\n",
        "del dict_dask_store\n",
        "shutdown_distributed(dict_client)\n",
        "del dict_client"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for k in [subgroup_code]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "da_imgs = dask_store[subgroup_norm]\n",
        "da_imgs_mtx = da_imgs.reshape(\n",
        "    da_imgs.shape[0],\n",
        "    int(np.prod(da_imgs.shape[1:]))\n",
        ")\n",
        "\n",
        "learner.components_ = dask_store[subgroup_dict].reshape(\n",
        "    (dask_store[subgroup_dict].shape[0], int(np.prod(da_imgs.shape[1:])))\n",
        ")\n",
        "\n",
        "code = learner.transform(da_imgs_mtx)\n",
        "code = code.T\n",
        "code = code.persist()\n",
        "\n",
        "dask_store[subgroup_code] = code\n",
        "\n",
        "#del learner\n",
        "#del code\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask_store[subgroup_code],\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import ipywidgets\n",
        "\n",
        "fig = plt.figure()\n",
        "fig.add_subplot(1,2,1)\n",
        "im = plt.imshow(np.zeros_like(dask_store[subgroup_dict][0]), vmin=-0.01, vmax=0.02)\n",
        "fig.add_subplot(1,2,2)\n",
        "line, = plt.plot([], [], lw=2)\n",
        "plt.axis([0, 1310, -1, 1])\n",
        "plt.show()\n",
        "\n",
        "@ipywidgets.interact(i=ipywidgets.IntSlider(min=0, max=len(dask_store[subgroup_dict])-1, step=1, value=0))\n",
        "def show_basis_code_plts(i):\n",
        "    im.set_array(dask_store[subgroup_dict][i] - dask_store[subgroup_dict].min(axis=0))\n",
        "    line.set_data(np.arange(len(dask_store[subgroup_code][i])), dask_store[subgroup_code][i])\n",
        "    fig.canvas.draw_idle()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import h5py\n",
        "\n",
        "with h5py.File(\"export.h5\", \"w\") as fh:\n",
        "    fh.require_dataset(subgroup_dict, shape=dask_store[subgroup_dict].shape, dtype=dask_store[subgroup_dict].dtype)\n",
        "    fh[subgroup_dict][...] = dask_store[subgroup_dict]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Postprocessing\n",
        "\n",
        "* `significance_threshold` (`float`): number of standard deviations below which to include in \"noise\" estimate\n",
        "* `wavelet_scale` (`int`): scale of wavelet transform to apply (should be the same as the one used above)\n",
        "* `noise_threshold` (`float`): number of units of \"noise\" above which something needs to be to be significant\n",
        "* `accepted_region_shape_constraints` (`dict`): if ROIs don't match this, reduce the `wavelet_scale` once.\n",
        "* `percentage_pixels_below_max` (`float`): upper bound on ratio of ROI pixels not at max intensity vs. all ROI pixels\n",
        "* `min_local_max_distance` (`float`): minimum allowable euclidean distance between two ROIs maximum intensities\n",
        "* `accepted_neuron_shape_constraints` (`dict`): shape constraints for ROI to be kept.\n",
        "\n",
        "* `alignment_min_threshold` (`float`): similarity measure of the intensity of two ROIs images used for merging.\n",
        "* `overlap_min_threshold` (`float`): similarity measure of the masks of two ROIs used for merging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "significance_threshold = 3.0\n",
        "wavelet_scale = 3\n",
        "noise_threshold = 3.0\n",
        "percentage_pixels_below_max = 0.8\n",
        "min_local_max_distance = 16.0\n",
        "\n",
        "alignment_min_threshold = 0.6\n",
        "overlap_min_threshold = 0.6\n",
        "\n",
        "\n",
        "for k in zarr_store.get(subgroup_post, {}).keys():\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[subgroup_post + \"/\" + k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_post]\n",
        "zarr_store.require_group(subgroup_post)\n",
        "\n",
        "\n",
        "imgs = dask_store._diskstore[subgroup_dict]\n",
        "da_imgs = da.from_array(imgs, chunks=((1,) + imgs.shape[1:]))\n",
        "\n",
        "result = block_postprocess_data_parallel(client)(da_imgs,\n",
        "                              **{\n",
        "                                    \"wavelet_denoising\" : {\n",
        "                                        \"estimate_noise\" : {\n",
        "                                            \"significance_threshold\" : significance_threshold\n",
        "                                        },\n",
        "                                        \"wavelet.transform\" : {\n",
        "                                            \"scale\" : wavelet_scale\n",
        "                                        },\n",
        "                                        \"significant_mask\" : {\n",
        "                                            \"noise_threshold\" : noise_threshold\n",
        "                                        },\n",
        "                                        \"accepted_region_shape_constraints\" : {\n",
        "                                            \"major_axis_length\" : {\n",
        "                                                \"min\" : 0.0,\n",
        "                                                \"max\" : 25.0\n",
        "                                            }\n",
        "                                        },\n",
        "                                        \"remove_low_intensity_local_maxima\" : {\n",
        "                                            \"percentage_pixels_below_max\" : percentage_pixels_below_max\n",
        "                                        },\n",
        "                                        \"remove_too_close_local_maxima\" : {\n",
        "                                            \"min_local_max_distance\" : min_local_max_distance\n",
        "                                        },\n",
        "                                        \"accepted_neuron_shape_constraints\" : {\n",
        "                                            \"area\" : {\n",
        "                                                \"min\" : 25,\n",
        "                                                \"max\" : 600\n",
        "                                            },\n",
        "                                            \"eccentricity\" : {\n",
        "                                                \"min\" : 0.0,\n",
        "                                                \"max\" : 0.9\n",
        "                                            }\n",
        "                                        }\n",
        "                                    },\n",
        "                                    \"merge_neuron_sets\" : {\n",
        "                                        \"alignment_min_threshold\" : alignment_min_threshold,\n",
        "                                        \"overlap_min_threshold\" : overlap_min_threshold,\n",
        "                                        \"fuse_neurons\" : {\n",
        "                                            \"fraction_mean_neuron_max_threshold\" : 0.01\n",
        "                                        }\n",
        "                                    }\n",
        "                              }\n",
        ")\n",
        "\n",
        "# Store projections\n",
        "dask_store.update(dict(zip(\n",
        "    [\"%s/%s\" % (subgroup_post, e) for e in result.dtype.names],\n",
        "    [result[e] for e in result.dtype.names]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[\"%s/%s\" % (subgroup_post, e)]\n",
        "        for e in result.dtype.names\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ROI and trace extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dask_io_remove(data_basename + postfix_rois + h5_ext, client)\n",
        "for k in [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j, subgroup_rois]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "with suppress(KeyError):\n",
        "    del zarr_store[subgroup_rois]\n",
        "zarr_store.require_group(subgroup_rois)\n",
        "\n",
        "\n",
        "da_roi_masks = dask_store[subgroup_post_mask]\n",
        "\n",
        "da_lbls = da.arange(\n",
        "    1,\n",
        "    len(da_roi_masks) + 1,\n",
        "    chunks=da_roi_masks.chunks[0],\n",
        "    dtype=np.uint64\n",
        ")\n",
        "da_lblimg = (\n",
        "    da_lbls[(slice(None),) + (da_roi_masks.ndim - 1) * (None,)] * \n",
        "    da_roi_masks.astype(np.uint64)\n",
        ").max(axis=0)\n",
        "\n",
        "dask_store.update(dict(zip(\n",
        "    [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j],\n",
        "    [da_roi_masks, da_roi_masks.astype(numpy.uint8), da_lblimg, da_lblimg.astype(numpy.uint8)]\n",
        ")))\n",
        "\n",
        "dask.distributed.progress(\n",
        "    dask.distributed.futures_of([\n",
        "        dask_store[e] for e in\n",
        "    [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j]\n",
        "    ]),\n",
        "    notebook=False\n",
        ")\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "with h5py.File(data_basename + postfix_rois + h5_ext, \"w\") as f2:\n",
        "    for k in [subgroup_rois_masks, subgroup_rois_masks_j, subgroup_rois_labels, subgroup_rois_labels_j]:\n",
        "        zarr.copy(dask_store._diskstore[k], f2)\n",
        "\n",
        "\n",
        "dask_io_remove(data_basename + postfix_traces + h5_ext, client)\n",
        "for k in [subgroup_traces]:\n",
        "    with suppress(KeyError):\n",
        "        del dask_store[k]\n",
        "\n",
        "\n",
        "# Load and prep data for computation.\n",
        "da_images = dask_store[subgroup_sub]\n",
        "da_masks = dask_store[subgroup_rois_masks]\n",
        "\n",
        "da_result = compute_traces(da_images, da_masks)\n",
        "\n",
        "# Store traces\n",
        "dask_store[subgroup_traces] = da_result\n",
        "\n",
        "dask.distributed.progress(dask_store[subgroup_traces], notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "with h5py.File(data_basename + postfix_traces + h5_ext, \"w\") as f2:\n",
        "    zarr.copy(dask_store._diskstore[subgroup_traces], f2)\n",
        "\n",
        "\n",
        "# View results\n",
        "imgs_min, imgs_max = 0, 100\n",
        "\n",
        "da_imgs = dask_store[subgroup_sub]\n",
        "\n",
        "da_imgs_min, da_imgs_max = da_imgs.min(), da_imgs.max()\n",
        "\n",
        "status = client.compute([da_imgs_min, da_imgs_max])\n",
        "dask.distributed.progress(status, notebook=False)\n",
        "print(\"\")\n",
        "\n",
        "imgs_min, imgs_max = [s.result() for s in status]\n",
        "\n",
        "mplsv = plt.figure(FigureClass=MPLViewer)\n",
        "mplsv.set_images(\n",
        "    da_imgs,\n",
        "    vmin=imgs_min,\n",
        "    vmax=imgs_max\n",
        ")\n",
        "\n",
        "lblimg = dask_store[subgroup_rois_labels].compute()\n",
        "lblimg_msk = numpy.ma.masked_array(lblimg, mask=(lblimg==0))\n",
        "\n",
        "mplsv.viewer.matshow(lblimg_msk, alpha=0.3, cmap=mpl.cm.jet)\n",
        "\n",
        "\n",
        "mskimg = None\n",
        "mskimg_j = None\n",
        "lblimg = None\n",
        "traces = None\n",
        "traces_j = None\n",
        "\n",
        "del mskimg\n",
        "del mskimg_j\n",
        "del lblimg\n",
        "del traces\n",
        "del traces_j"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# End of workflow. Shutdown cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import dask.distributed\n",
        "from nanshe_workflow.par import shutdown_distributed\n",
        "\n",
        "try:\n",
        "    del dask_store\n",
        "except NameError:\n",
        "    pass\n",
        "\n",
        "client = dask.distributed.client.default_client()\n",
        "\n",
        "shutdown_distributed(client)\n",
        "\n",
        "client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Prepare interactive projection graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy\n",
        "import numpy as np\n",
        "\n",
        "import bokeh.plotting\n",
        "import bokeh.plotting as bp\n",
        "\n",
        "import bokeh.io\n",
        "import bokeh.io as bio\n",
        "\n",
        "import bokeh.embed\n",
        "import bokeh.embed as be\n",
        "\n",
        "from bokeh.models.mappers import LinearColorMapper\n",
        "\n",
        "import webcolors\n",
        "\n",
        "from bokeh.models import CustomJS, ColumnDataSource, HoverTool\n",
        "from bokeh.models.layouts import Row\n",
        "\n",
        "from builtins import (\n",
        "    map as imap,\n",
        "    range as irange\n",
        ")\n",
        "\n",
        "from past.builtins import basestring\n",
        "\n",
        "import nanshe_workflow\n",
        "from nanshe_workflow.data import io_remove, open_zarr\n",
        "from nanshe_workflow.vis import (\n",
        "    get_rgb_array, get_rgba_array, get_all_greys, masks_to_contours_2d,\n",
        "    generate_cdn, write_html,\n",
        ")\n",
        "from nanshe_workflow.util import gzip_compress, hash_file, indent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mskimg = zarr_store[subgroup_rois_masks][...]\n",
        "\n",
        "traces = zarr_store[subgroup_traces][...]\n",
        "\n",
        "imgproj_mean = zarr_store[subgroup_proj_max][...]\n",
        "imgproj_max = zarr_store[subgroup_proj_mean][...]\n",
        "imgproj_std = zarr_store[subgroup_proj_std][...]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Result visualization\n",
        "\n",
        "* `proj_img` (`str` or `list` of `str`): which projection or projections to plot (e.g. \"max\", \"mean\", \"std\").\n",
        "* `block_size` (`int`): size of each point on any dimension in the image in terms of pixels.\n",
        "* `roi_alpha` (`float`): transparency of the ROIs in a range of [0.0, 1.0].\n",
        "* `roi_border_width` (`int`): width of the line border on each ROI.\n",
        "\n",
        "<br>\n",
        "\n",
        "* `trace_plot_width` (`int`): width of the trace plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "proj_img = \"std\"\n",
        "block_size = 1\n",
        "roi_alpha = 0.3\n",
        "roi_border_width = 3\n",
        "trace_plot_width = 500\n",
        "\n",
        "\n",
        "bio.curdoc().clear()\n",
        "\n",
        "grey_range = get_all_greys()\n",
        "grey_cm = LinearColorMapper(grey_range)\n",
        "\n",
        "colors_rgb = get_rgb_array(len(mskimg))\n",
        "colors_rgb = colors_rgb.tolist()\n",
        "colors_rgb = list(imap(webcolors.rgb_to_hex, colors_rgb))\n",
        "\n",
        "mskctr_pts_y, mskctr_pts_x = masks_to_contours_2d(mskimg)\n",
        "\n",
        "mskctr_pts_dtype = np.min_scalar_type(max(mskimg.shape[1:]) - 1)\n",
        "mskctr_pts_y = [np.array(_, dtype=mskctr_pts_dtype) for _ in mskctr_pts_y]\n",
        "mskctr_pts_x = [np.array(_, dtype=mskctr_pts_dtype) for _ in mskctr_pts_x]\n",
        "\n",
        "mskctr_srcs = ColumnDataSource(data=dict(x=mskctr_pts_x, y=mskctr_pts_y, color=colors_rgb))\n",
        "\n",
        "\n",
        "if isinstance(proj_img, basestring):\n",
        "    proj_img = [proj_img]\n",
        "else:\n",
        "    proj_img = list(proj_img)\n",
        "\n",
        "\n",
        "proj_plot_width = block_size*mskimg.shape[2]\n",
        "proj_plot_height = block_size*mskimg.shape[1]\n",
        "plot_projs = []\n",
        "\n",
        "if \"max\" in proj_img:\n",
        "    plot_max = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Max Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_max.image(image=[numpy.flipud(imgproj_max)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[imgproj_max.shape[1]], dh=[imgproj_max.shape[0]], color_mapper=grey_cm)\n",
        "    plot_max.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_max.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_max.axis)):\n",
        "        plot_max.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_max)\n",
        "\n",
        "\n",
        "if \"mean\" in proj_img:\n",
        "    plot_mean = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Mean Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_mean.image(image=[numpy.flipud(imgproj_mean)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[mskimg.shape[2]], dh=[mskimg.shape[1]], color_mapper=grey_cm)\n",
        "    plot_mean.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_mean.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_mean.axis)):\n",
        "        plot_mean.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_mean)\n",
        "\n",
        "\n",
        "if \"std\" in proj_img:\n",
        "    plot_std = bp.Figure(plot_width=proj_plot_width, plot_height=proj_plot_height,\n",
        "                         x_range=[0, mskimg.shape[2]], y_range=[mskimg.shape[1], 0],\n",
        "                         tools=[\"tap\", \"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"],\n",
        "                         title=\"Std Dev Projection with ROIs\", border_fill_color=\"black\")\n",
        "    plot_std.image(image=[numpy.flipud(imgproj_std)], x=[0], y=[mskimg.shape[1]],\n",
        "                   dw=[mskimg.shape[2]], dh=[mskimg.shape[1]], color_mapper=grey_cm)\n",
        "    plot_std.patches('x', 'y', source=mskctr_srcs, alpha=roi_alpha, line_width=roi_border_width, color=\"color\")\n",
        "\n",
        "    plot_std.outline_line_color = \"white\"\n",
        "    for i in irange(len(plot_std.axis)):\n",
        "        plot_std.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "    plot_projs.append(plot_std)\n",
        "\n",
        "\n",
        "all_tr_dtype_srcs = ColumnDataSource(data=dict(traces_dtype=traces.dtype.type(0)[None]))\n",
        "all_tr_shape_srcs = ColumnDataSource(data=dict(traces_shape=traces.shape))\n",
        "all_tr_srcs = ColumnDataSource(data=dict(\n",
        "    traces=numpy.frombuffer(\n",
        "        gzip_compress(traces.tobytes()),\n",
        "        dtype=np.uint8\n",
        "    )\n",
        "))\n",
        "tr_srcs = ColumnDataSource(data=dict(times_sel=[], traces_sel=[], colors_sel=[]))\n",
        "plot_tr = bp.Figure(plot_width=trace_plot_width, plot_height=proj_plot_height,\n",
        "                    x_range=(0.0, float(traces.shape[1])), y_range=(float(traces.min()), float(traces.max())),\n",
        "                    tools=[\"pan\", \"box_zoom\", \"wheel_zoom\", \"save\", \"reset\"], title=\"ROI traces\",\n",
        "                    background_fill_color=\"black\", border_fill_color=\"black\")\n",
        "plot_tr.multi_line(\"times_sel\", \"traces_sel\", source=tr_srcs, color=\"colors_sel\")\n",
        "\n",
        "plot_tr.outline_line_color = \"white\"\n",
        "for i in irange(len(plot_tr.axis)):\n",
        "    plot_tr.axis[i].axis_line_color = \"white\"\n",
        "\n",
        "plot_projs.append(plot_tr)\n",
        "\n",
        "\n",
        "mskctr_srcs.selected.js_on_change(\"indices\", CustomJS(\n",
        "    args=dict(\n",
        "        mskctr_srcs=mskctr_srcs,\n",
        "        all_tr_dtype_srcs=all_tr_dtype_srcs,\n",
        "        all_tr_shape_srcs=all_tr_shape_srcs,\n",
        "        all_tr_srcs=all_tr_srcs,\n",
        "        tr_srcs=tr_srcs\n",
        "    ), code=\"\"\"\n",
        "    var range = function(n){ return Array.from(Array(n).keys()); };\n",
        "\n",
        "    var traces_not_decoded = (all_tr_dtype_srcs.data['traces_dtype'] == 0);\n",
        "    var traces_dtype = all_tr_dtype_srcs.data['traces_dtype'].constructor;\n",
        "    var traces_shape = all_tr_shape_srcs.data['traces_shape'];\n",
        "    var trace_len = traces_shape[1];\n",
        "    var traces = all_tr_srcs.data['traces'];\n",
        "    if (traces_not_decoded) {\n",
        "        traces = window.pako.inflate(traces);\n",
        "        traces = new traces_dtype(traces.buffer);\n",
        "        all_tr_srcs.data['traces'] = traces;\n",
        "        all_tr_dtype_srcs.data['traces_dtype'] = 1;\n",
        "    }\n",
        "\n",
        "    var inds = cb_obj['1d'].indices;\n",
        "    var colors = mskctr_srcs.data['color'];\n",
        "    var selected = tr_srcs.data;\n",
        "\n",
        "    var times = range(trace_len);\n",
        "\n",
        "    selected['times_sel'] = [];\n",
        "    selected['traces_sel'] = [];\n",
        "    selected['colors_sel'] = [];\n",
        "\n",
        "    for (i = 0; i < inds.length; i++) {\n",
        "        var inds_i = inds[i];\n",
        "        var trace_i = traces.slice(trace_len*inds_i, trace_len*(inds_i+1));\n",
        "        var color_i = colors[inds_i];\n",
        "\n",
        "        selected['times_sel'].push(times);\n",
        "        selected['traces_sel'].push(trace_i);\n",
        "        selected['colors_sel'].push(color_i);\n",
        "    }\n",
        "\n",
        "    tr_srcs.change.emit();\n",
        "\"\"\"))\n",
        "\n",
        "\n",
        "plot_group = Row(*plot_projs)\n",
        "\n",
        "\n",
        "# Clear out the old HTML file before writing a new one.\n",
        "io_remove(data_basename + postfix_html + html_ext)\n",
        "\n",
        "\n",
        "script, div = be.components(plot_group)\n",
        "cdn = \"\\n\" + generate_cdn(\"sha384\") + \"\\n\"\n",
        "cdn += \"\"\"\n",
        "<script type=\"text/javascript\" src=\"{url}\" integrity=\"{integrity}\" crossorigin=\"anonymous\"></script>\n",
        "\"\"\".format(\n",
        "    url=\"https://cdnjs.cloudflare.com/ajax/libs/pako/{ver}/pako_inflate.min.js\",\n",
        "    integrity=\"{sha_type}-{sha_value}\",\n",
        ").format(\n",
        "    ver=\"1.0.6\",\n",
        "    sha_type=\"sha384\",\n",
        "    sha_value=\"vfctOCT+kAyhRRvZr0t63Ktb6zOZrCbLW9CIyQr9G4UMhKAabPpM3iDOI2lnXsX4\"\n",
        ")\n",
        "cdn += \"\\n\"\n",
        "\n",
        "write_html(data_basename + postfix_html + html_ext, data_basename + postfix_html, div, script, cdn)\n",
        "\n",
        "\n",
        "from IPython.display import display, IFrame\n",
        "display(IFrame(data_basename + postfix_html + html_ext, \"100%\", 1.05*proj_plot_height))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test teardown. Ignore warnings during production runs.\n",
        "\n",
        "%run ./teardown_tests.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "widgets": {
      "state": {},
      "version": "1.2.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
